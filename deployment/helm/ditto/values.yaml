# Copyright (c) 2023 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Default values for ditto.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

serviceAccount:
  # create controls whether a service account should be created
  create: true
  # name is the name of the service account to use
  #  If not set and create is true, a name is generated using the fullname template
  name:
  # assumeAwsIamRole specifies whether to assume an AWS IAM Role for Service Accounts (IRSA).
  # Set to true to use IRSA, which allows the pod to assume an IAM role.
  # When set to true, ensure that awsRoleArn is specified.
  assumeAwsIamRole: false
  # assumedAwsRoleArn is the Amazon Resource Name (ARN) of the IAM role to be assumed by the service account.
  # This is required if assumeAwsIamRole is set to true.
  # Example: arn:aws:iam::<account-id>:role/<role-name>
  assumedAwsRoleArn: ""

rbac:
  # enabled controls whether RBAC resources will be created
  enabled: true

nameOverride: ""
fullnameOverride: ""

## ----------------------------------------------------------------------------
## global configuration shared by all components
global:
  # cluster holds the configuration for the Ditto/Pekko cluster
  cluster:
    # requiredContactPoints defines the total amount of replicas in the Ditto cluster
    #  only if this amount is "seen" during cluster formation, the cluster can form itself
    requiredContactPoints: 5
    # ddata holds the "Distributed Data" configuration:
    ddata:
      # numberOfShards defines whether ddata structures should be shared (if >1)
      #  this is needed in case a lot of event subscribers (thousands) are connected simultaneously
      numberOfShards: 1
      # maxDeltaElements defines how many elements should be synced with a single cluster message
      #  if numberOfShards is > 1, it makes sense to keep maxDeltaElements lower
      #  so that the message size for remoting is not exceeding the configured max message size
      maxDeltaElements: 1
    # numberOfShards configures the sharding applied for things/policies/connections based on their ID
    #  as a rule of thumb: should be factor ten of the amount of cluster replicas for an entity
    numberOfShards: 50
    # downingStableAfter is a configuration of the Pekko SBR (split brain resolver)
    #  how to find the right value: https://pekko.apache.org/docs/pekko/current/split-brain-resolver.html
    downingStableAfter: 15s
    # downAllWhenUnstable is a configuration of the Pekko SBR (split brain resolver)
    downAllWhenUnstable: "on"
  # limits contains information about limit configuration, e.g. towards max. entity and payload sizes
  limits:
    # clusterMaxFramesize the maximum serialized message size in the cluster, including header data, default: 256 KiB
    clusterMaxFramesize: 256k
    # thingsMaxSize the maximum possible size of "Thing" entities, default: 100k
    thingsMaxSize: 100k
    # policiesMaxSize the maximum possible size of "Policy" entities, default: 100k
    policiesMaxSize: 100k
    # policiesMaxImports the maximum possible number of allowed imports a Policy can have
    policiesMaxImports: 10
    # messagesMaxSize the maximum possible size of "Messages" (their payload), default: 250k
    messagesMaxSize: 250k
    # maxHeadersSize the maximum possible size of Ditto headers (e.g. all HTTP headers are mapped to Ditto headers), default: 5k
    maxHeadersSize: 5k
    # maxAuthSubjectsCount the maximum possible number of authorization subjects in Ditto headers, default: 100
    maxAuthSubjectsCount: 100
  # basicAuthUsers configures several user/password combinations which the nginx of the Ditto chart will authenticate
  basicAuthUsers:
  # - user: ditto
  #   password: ditto
  # - user: jane
  #   password: janesPw
  # existingSecret contains the name of existing secret containing user and password
  #  format: ${user}:${password}, where secret key is ${user} and value is ${password}
  #  example creating secret for users ditto and jane:
  #    kubectl create secret generic ditto-basic-auth --from-literal ditto=ditto --from-literal jane=janesPw
  #  if not set then basicAuthUsers values are used.
  existingSecret:
  # hashedBasicAuthUsers configures a list of hashed .htpasswd username/password entries
  hashedBasicAuthUsers: []
  # jwtOnly controls whether only OpenID-Connect authentication is supported
  #  if false, both OpenID-Connect and basicAuth via nginx (see above "basicAuthUsers" and "hashedBasicAuthUsers") is used
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#openid-connect
  jwtOnly: false
  # jvmOptions defines the JVM options applied to all Ditto services running in the JVM, it is put in JAVA_TOOL_OPTIONS
  jvmOptions: >
    -XX:+ExitOnOutOfMemoryError
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:HeapDumpPath=/opt/ditto/dumps/oom.bin
    -XX:+UseContainerSupport
    -XX:+UseStringDeduplication
    -Xss512k
    -XX:MaxMetaspaceSize=256m
    -XX:+UseG1GC
    -Djava.net.preferIPv4Stack=true
  pekkoOptions: >
    -Dpekko.management.cluster.bootstrap.contact-point-discovery.port-name=management
    -Dpekko.http.client.parsing.max-chunk-size=2m
    -Dpekko.cluster.failure-detector.threshold=15.0
    -Dpekko.cluster.failure-detector.expected-response-after=3s
    -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=7s
    -Dpekko.persistence.journal-plugin-fallback.recovery-event-timeout=30s
    -Dpekko.persistence.max-concurrent-recoveries=100
    -Dpekko.cluster.sharding.updating-state-timeout=20s
    -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s
  # timezone defines the timezone to configure the JVM with
  timezone: Europe/Berlin
  # additionalAnnotations contains additional annotations to apply to the deployment template of Ditto services
  additionalAnnotations: {}
  # imagePullSecrets will be added to every deployment
  imagePullSecrets: []
  # proxyPart configures a reverse proxy part to be added in front of the Ditto API endpoints:
  proxyPart: ""
  # prometheus holds the Prometheus specific configuration
  prometheus:
    # enabled controls whether scrape config annotation will be added to pod templates
    enabled: true
    # path where prometheus metric will be provided
    path: "/"
    # port where prometheus metrics will be provided
    port: 9095
  # featureFlags contains feature flags enabling/disabling certain features
  featureFlags:
    # mergeThingsEnabled controls whether MergeThing commands (patching of things) are enabled or not
    mergeThingsEnabled: true
    # wotIntegrationEnabled controls whether the Web of Things (WoT) integration is enabled or not
    wotIntegrationEnabled: true
    # historicalApisEnabled controls whether the historical APIs (using the event journal) are enabled or not
    historicalApisEnabled: true
    # preserveKnownMqttHeadersEnabled controls whether known MQTT headers (e.g., mqtt.topic) are preserved in outgoing messages
    preserveKnownMqttHeadersEnabled: true
    # jsonKeyValidationEnabled controls whether for each json object, each JSON key should be validated against a regex pattern
    #  excluding control characters to be used as JSON keys. This can have quite a performance impact.
    jsonKeyValidationEnabled: true
  # logging the logging configuration for Ditto
  logging:
    # sysout holds the logging to SYSOUT config
    sysout:
      # enabled defines whether to log to SYSOUT
      enabled: true
    # logstash configures if logs should be pushed to a logstash endpoint
    logstash:
      # enabled defines whether to log to logstash
      enabled: false
      # endpoint configures the logstash endpoint to send logs to
      endpoint: ""
      # logstash write buffer size
      writeBufferSize: 8192
      # logstash ring buffer size
      ringBufferSize: 8192
    # logFiles defines logging to log files config
    logFiles:
      # enabled whether to write logs to log files
      #  log files can be found on the host under /var/log/ditto
      enabled: false
    # customConfigFile configures that a custom "Logback" config file should be used instead of the one bundled
    #  with Ditto on the classpath
    customConfigFile:
      # enabled if enabled, a custom logback.xml file added to the Ditto containers will be used for logging configuration
      enabled: true
      # fileName passed as Java system property "-Dlogback.configurationFile"
      fileName: logback.xml
  # metrics configuration for Ditto
  metrics:
    # metricsPrefix defines a prefix to use for all Ditto created metrics (counters, gauges, histograms)
    metricsPrefix: ""
    # systemMetrics contains the configuration for obtaining system metrics (via Kamon)
    systemMetrics:
      # enabled if enabled, system metrics are gathered
      enabled: true
  # tracing configuration for Ditto
  tracing:
    # enabled whether tracing (via OpenTelemetry) is enabled
    enabled: false
    # otelTraceReporterEnabled whether reporting traces via the OLTP endpoint should be activated
    otelTraceReporterEnabled: false
    # otelExporterOtlpEndpoint the OTLP endpoint to report traces to
    otelExporterOtlpEndpoint: "http://localhost:4317"
    # sampler the tracing sampler to use
    #  can be one of:
    #   - always: report all traces.
    #   - never:  don't report any trace.
    #   - random: randomly decide using the probability defined in the random-sampler.probability setting.
    #   - adaptive: keeps dynamic samplers for each operation while trying to achieve a set throughput goal.
    sampler: never
    # randomSampler configures the 'random' sampler
    randomSampler:
      # probability configures the probability of a span being sampled, must be a value between 0 and 1
      probability: 0.01
    # adaptiveSampler configures the 'adaptive' sampler
    adaptiveSampler:
      # throughput the throughput goal trying to achieve with the adaptive sampler
      throughput: 600
  # podDeletionCostPatching hold configuration for whether to patch "oldest" members of the Ditto cluster with higher
  #  k8s pod-deletion-cost annotations so that they are downed last when e.g. doing an upgrade
  podDeletionCostPatching:
    # user defines the user to run the pod-deletion-cost annotation patching job as
    user: 1000
    # group defines the group to run the pod-deletion-cost annotation patching job as
    group: 1000
    # runAsNonRoot defines whether the pod-deletion-cost annotation patching job should run as non-root
    runAsNonRoot: true
    # allowPrivilegeEscalation defines whether the pod-deletion-cost annotation patching job should allow privilege escalation
    allowPrivilegeEscalation: false
    # enabled whether the pod-deletion-cost annotation patching should be enabled
    enabled: true
    # annotations defines k8s annotations to add to corresponding jobs
    annotations: {}
    image:
      # repository for the pod-deletion-cost annotation patching job docker image
      repository: public.ecr.aws/h0h9t7p1/alpine-bash-curl-jq
      # tag for the pod-deletion-cost annotation patching job docker image
      tag: latest
      # pullPolicy for the pod-deletion-cost annotation patching job docker image
      pullPolicy: IfNotPresent


## ----------------------------------------------------------------------------
## dbconfig for mongodb connections
##  will be handled as k8s secret as connection uri might contain auth credentials
dbconfig:
  # policies the MongoDB configuration for Ditto "policies" service
  policies:
    uri: mongodb://#{PLACEHOLDER_MONGODB_HOSTNAME}#:27017/ditto
    ssl: false
    # useAwsIamRole specifies whether to use an AWS IAM Role for Service Accounts (IRSA) which the pod assumes.
    useAwsIamRole: false
    # awsRegion defines the AWS region - if this is an empty string, the AWS SDK will attempt to identify the
    #  region automatically based on the environment and eventually EC2 instances
    awsRegion: ""
    # awsRoleArn is the Amazon Resource Name (ARN) of the IAM role to be assumed by the pod.
    #  This is required if useAwsIamRole is set to true.
    #  Example: arn:aws:iam::<account-id>:role/<role-name>
    awsRoleArn: ""
    # awsSessionName is the name of the session when assuming the AWS role.
    #  This can be used to identify the session in logs or IAM policies.
    awsSessionName: "dittoSession"
  # things the MongoDB configuration for Ditto "things" service
  things:
    uri: mongodb://#{PLACEHOLDER_MONGODB_HOSTNAME}#:27017/ditto
    ssl: false
    # useAwsIamRole specifies whether to use an AWS IAM Role for Service Accounts (IRSA) which the pod assumes.
    useAwsIamRole: false
    # awsRegion defines the AWS region - if this is an empty string, the AWS SDK will attempt to identify the
    #  region automatically based on the environment and eventually EC2 instances
    awsRegion: ""
    # awsRoleArn is the Amazon Resource Name (ARN) of the IAM role to be assumed by the pod.
    #  This is required if useAwsIamRole is set to true.
    #  Example: arn:aws:iam::<account-id>:role/<role-name>
    awsRoleArn: ""
    # awsSessionName is the name of the session when assuming the AWS role.
    #  This can be used to identify the session in logs or IAM policies.
    awsSessionName: "dittoSession"
  # connectivity the MongoDB configuration for Ditto "connectivity" service
  connectivity:
    uri: mongodb://#{PLACEHOLDER_MONGODB_HOSTNAME}#:27017/ditto
    ssl: false
    # useAwsIamRole specifies whether to use an AWS IAM Role for Service Accounts (IRSA) which the pod assumes.
    useAwsIamRole: false
    # awsRegion defines the AWS region - if this is an empty string, the AWS SDK will attempt to identify the
    #  region automatically based on the environment and eventually EC2 instances
    awsRegion: ""
    # awsRoleArn is the Amazon Resource Name (ARN) of the IAM role to be assumed by the pod.
    #  This is required if useAwsIamRole is set to true.
    #  Example: arn:aws:iam::<account-id>:role/<role-name>
    awsRoleArn: ""
    # awsSessionName is the name of the session when assuming the AWS role.
    #  This can be used to identify the session in logs or IAM policies.
    awsSessionName: "dittoSession"
  # thingsSearch the MongoDB configuration for Ditto "things-search" service
  thingsSearch:
    uri: mongodb://#{PLACEHOLDER_MONGODB_HOSTNAME}#:27017/ditto
    ssl: false
    # useAwsIamRole specifies whether to use an AWS IAM Role for Service Accounts (IRSA) which the pod assumes.
    useAwsIamRole: false
    # awsRegion defines the AWS region - if this is an empty string, the AWS SDK will attempt to identify the
    #  region automatically based on the environment and eventually EC2 instances
    awsRegion: ""
    # awsRoleArn is the Amazon Resource Name (ARN) of the IAM role to be assumed by the pod.
    #  This is required if useAwsIamRole is set to true.
    #  Example: arn:aws:iam::<account-id>:role/<role-name>
    awsRoleArn: ""
    # awsSessionName is the name of the session when assuming the AWS role.
    #  This can be used to identify the session in logs or IAM policies.
    awsSessionName: "dittoSession"
  ## If following property is set, an existing secret will be used to retrieve the mongodb connectionUris from.
  # uriSecret: my-uri-secret

## ----------------------------------------------------------------------------
## ingress configures the Ingress
ingress:
  # enabled whether Ingress should be enabled as alternative to the contained nginx
  enabled: false
  # className is the 'ingressClassName' to configure in the Ingress spec
  className: nginx
  # host the hostname of the Ingress shared for all: api, ws and ui
  host: localhost
  # defaultBackendSuffix the suffix to add to the internal fullname to use as Ingress "defaultBackend"
  defaultBackendSuffix: nginx
  # annotations common annotations for all 3 Ingresses of Ditto
  controller:
    # enabled whether Ingress controller should be enabled
    enabled: false
    # replicaCount configuration for the ingress controller
    replicaCount: 1
    # Exposes the ingress controller settings in order to configure its behavior.
    config:
      # Sets the number of worker processes that should be started by the ingress controller.
      # Depending on the load of the ingress controller, this value can be increased or decreased.
      # When not sure setting it to auto is also fine, but take cares as that will increase RAM usage.
      workerProcesses: 2
      # Sets the maximum number of simultaneous connections that can be opened by each worker process.
      # 0 will use the value of max-worker-open-files. default: 16384
      workerConnections: 0
      # Sets the maximum number of files that can be opened by each worker process.
      # The default of 0 means "max open files (system's limit) - 1024".
      workerOpenFiles: 0
    updateStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
    # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
    #  of its containers crashing, for it to be considered available
    #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
    minReadySeconds: 10
    # as NGINX Ingress Controller on its pod shutdown tends to interrupt connections, we need to include
    # some wait time so that existing connections are fully handled before the pod is really shut down.
    # ref: https://medium.com/codecademy-engineering/kubernetes-nginx-and-zero-downtime-in-production-2c910c6a5ed8
    preStopWait: 15
    # specify how many old ReplicaSets for ingress controller deployment will be retained
    # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#clean-up-policy
    revisionHistoryLimit: 5
    # resources configures the resources available/to use for the policies service
    resources:
      # cpu defines the "required" CPU of a node so that the service is placed there
      cpu: 0.75
      # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
      memoryMi: 1024
      # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
      ephemeralStorageMi: 2048
    # namespace for ingress controller, managed by helm, should not be created manually
    namespace: ingress-nginx
    # Ingress-NGINX version. Check Supported Versions table from https://github.com/kubernetes/ingress-nginx to match k8s version.
    nginxIngressVersion: "v1.11.5"
    # Nginx Version. Check Supported Versions table from https://github.com/kubernetes/ingress-nginx to match k8s version.
    nginxVersion: "1.25.5"
    # Pod topology spread constraints for nginx-ingress controller
    # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
    topologySpreadConstraints:
      maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  annotations:
    nginx.ingress.kubernetes.io/service-upstream: "true"
    nginx.ingress.kubernetes.io/server-snippet: |
      charset utf-8;
      default_type application/json;
      chunked_transfer_encoding off;

      send_timeout 70; # seconds, default: 60
      client_header_buffer_size 8k; # allow longer URIs + headers (default: 1k)
      large_client_header_buffers 4 16k;

      proxy_http_version 1.1;
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Forwarded-Proto $scheme;
      proxy_set_header X-Forwarded-For $remote_addr;
      proxy_set_header Host $host;
  # api the /api, /stats and /overall Ingress configuration
  api:
    # paths configures ingress paths
    paths:
      # negative lookahead, so we don't accept /api/2/connections, which is devops responsibility
      - path: /api/2/(?!connections)
        pathType: ImplementationSpecific
        backendSuffix: gateway
      - path: /stats
        backendSuffix: gateway
      - path: /overall
        backendSuffix: gateway
    kubernetesAuthAnnotations: |
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: {{ .Release.Name }}-nginx-ingress-htpasswd
      nginx.ingress.kubernetes.io/auth-realm: 'Authentication required to use HTTP API!'
    # annotations defines k8s annotations to add to the Ingress
    annotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "10"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "70"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "70"
      nginx.ingress.kubernetes.io/proxy-next-upstream: "error timeout http_502"
      nginx.ingress.kubernetes.io/proxy-next-upstream-tries: "4"
      nginx.ingress.kubernetes.io/proxy-next-upstream-timeout: "50"
      nginx.ingress.kubernetes.io/proxy-buffer-size: "16k"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        set $cors $http_origin;

        # Allow-listed origins for CORS - enforces https for those
        #if ($http_origin ~ '^https://eclipse-ditto\.github\.io(:\d+)?)$') {
        #  set $cors $http_origin;
        #}
        # Allows http for localhost (on any port)
        #if ($http_origin ~ '^http://(localhost|127\.0\.0\.1)(:\d+)?') {
        #  set $cors $http_origin;
        #}

        if ($cors != "") {
          add_header 'Access-Control-Allow-Origin' '$cors' always;
          add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, PATCH, DELETE, OPTIONS' always;
          add_header 'Access-Control-Allow-Credentials' 'true' always;
          add_header 'Access-Control-Allow-Headers' '$http_access_control_request_headers' always;
          add_header 'Access-Control-Expose-Headers' 'correlation-id, response-required, dry-run, channel, etag, ditto-originator, requested-acks, timeout, location, ditto-metadata, traceparent, tracestate, entity-revision' always;
        }

        if ($request_method = 'OPTIONS') {
          # Tell client that this pre-flight info is valid for 20 days
          add_header 'Access-Control-Max-Age' 1728000;
          add_header 'Access-Control-Allow-Origin' '$cors' always;
          add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, PATCH, DELETE, OPTIONS' always;
          add_header 'Access-Control-Allow-Credentials' 'true' always;
          add_header 'Access-Control-Allow-Headers' '$http_access_control_request_headers' always;
          add_header 'Access-Control-Expose-Headers' 'correlation-id, response-required, dry-run, channel, etag, ditto-originator, requested-acks, timeout, location, ditto-metadata, traceparent, tracestate, entity-revision' always;
          add_header 'Content-Type' 'text/plain charset=UTF-8';
          add_header 'Content-Length' 0;
          return 204;
        }

        # security relevant headers:
        add_header "Content-Security-Policy" "default-src 'none'; frame-ancestors 'none'" always;
        add_header "Strict-Transport-Security" "max-age=63072000; includeSubdomains;" always;
        add_header "Cache-Control" "no-cache" always;
        add_header "X-Content-Type-Options" "nosniff" always;
        add_header "X-Frame-Options" "SAMEORIGIN" always;
        add_header "X-XSS-Protection" "1; mode=block" always;

        # set ditto-specific forwarded headers
        proxy_set_header X-Forwarded-User $remote_user;
        proxy_set_header x-ditto-pre-authenticated "nginx:$remote_user";
  # ws the /ws (WebSocket) Ingress configuration
  ws:
    # paths configures ingress paths
    paths:
      - path: /ws
        backendSuffix: gateway
    # annotations defines k8s annotations to add to the Ingress
    annotations:
      nginx.ingress.kubernetes.io/proxy-send-timeout: "86400"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
      nginx.ingress.kubernetes.io/proxy-next-upstream: "error timeout http_502"
      nginx.ingress.kubernetes.io/proxy-next-upstream-tries: "4"
      nginx.ingress.kubernetes.io/proxy-next-upstream-timeout: "50"
      nginx.ingress.kubernetes.io/proxy-buffering: "off"
  # the / Ingress configuration for serving the landing page and static resources
  root:
    # paths configures ingress paths
    paths:
      - path: /
        pathType: Exact
        backendSuffix: nginx
      - path: /index.html
        pathType: ImplementationSpecific
        backendSuffix: nginx
      - path: /ditto-up.svg
        pathType: ImplementationSpecific
        backendSuffix: nginx
      - path: /ditto-down.svg
        pathType: ImplementationSpecific
        backendSuffix: nginx
    # annotations defines k8s annotations to add to the Ingress
    annotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "10"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        # security relevant headers:
        add_header "Content-Security-Policy" "default-src 'self'; script-src-elem 'self' 'sha256-Kq9eqc/CtX2tgHPLJUEf8vDO9eNiGaRBrwAYYXTroVc='  https://cdnjs.cloudflare.com https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net https://cdnjs.cloudflare.com; worker-src 'self' blob:; object-src 'none';" always;
        add_header "Strict-Transport-Security" "max-age=63072000; includeSubdomains;" always;
        add_header "Cache-Control" "no-cache" always;
        add_header "X-Content-Type-Options" "nosniff" always;
        add_header "X-Frame-Options" "SAMEORIGIN" always;
        add_header "X-XSS-Protection" "1; mode=block" always;
  # ui the /ui and /apidoc Ingress configuration
  ui:
    # paths configures ingress paths
    paths:
      - path: /
        pathType: Exact
        backendSuffix: nginx
      - path: /apidoc(/|$)(.*)
        pathType: ImplementationSpecific
        backendSuffix: swaggerui
      - path: /ui(/|$)(.*)
        pathType: ImplementationSpecific
        backendSuffix: dittoui
    # annotations defines k8s annotations to add to the Ingress
    annotations:
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$2
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "10"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        # security relevant headers:
        add_header "Content-Security-Policy" "default-src 'self'; script-src-elem 'self' 'sha256-Ve/Ec/6YDEeTc+9y+QCJ+e9OhyGWAj3bYxCzNGfOn6U=' 'sha256-Kq9eqc/CtX2tgHPLJUEf8vDO9eNiGaRBrwAYYXTroVc=' https://cdnjs.cloudflare.com https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net https://cdnjs.cloudflare.com; img-src 'self' data: https://raw.githubusercontent.com; font-src 'self' https://cdnjs.cloudflare.com; worker-src 'self' blob:; connect-src 'self' localhost http://localhost:8080; object-src 'none';" always;
        add_header "Strict-Transport-Security" "max-age=63072000; includeSubdomains;" always;
        add_header "Cache-Control" "no-cache" always;
        add_header "X-Content-Type-Options" "nosniff" always;
        add_header "X-Frame-Options" "SAMEORIGIN" always;
        add_header "X-XSS-Protection" "1; mode=block" always;
        rewrite ^(/ui)$ $1/ permanent;
        rewrite ^(/apidoc)$ $1/ permanent;
  # devops the /devops, /api/2/connections, /status and /health commands Ingress configuration
  devops:
    # paths configures ingress paths
    paths:
      - path: /devops
        backendSuffix: gateway
      - path: /status
        backendSuffix: gateway
      - path: /health
        backendSuffix: gateway
      - path: /api/2/connections
        backendSuffix: gateway
    # annotations defines k8s annotations to add to the Ingress
    # if undefined, api ingress annotations are reused
    annotations:
  # tls configures the TLS for ingress
  tls: []
  #  - secretName: ditto-tls
  #    hosts:
  #      - localhost


## ----------------------------------------------------------------------------
## openshift configures the OpenShift deployment
openshift:
  # enabled whether to deploy to OpenShift
  enabled: false
  # routes the OpenShift Routes
  routes:
    # enabled whether OpenShift routes are enabled
    enabled: false
    # annotations define k8s annotations to apply for the routes
    annotations: {}
    # host: ""
    # targetPort configures the target port
    targetPort: http
    # tlsTermination: "edge"
    # tlsInsecurePolicy: "Redirect"
  # securityContext the security context for OpenShift
  securityContext: {}

## ----------------------------------------------------------------------------
## pekko holds the Pekko actor configuration
##  ref: https://pekko.apache.org/docs/pekko/current/typed/index.html
pekko:
  # actorSystemName defines the actor/cluster name of the Ditto cluster
  actorSystemName: ditto-cluster
  # remoting holds configuration for the Pekko cluster remoting
  remoting:
    # port defines the Port to use for remoting
    port: 2551
  # mgmthttp holds configuration for the Pekko cluster management
  mgmthttp:
    # port defines the Port to use for pekko http management
    port: 7626

# Set "dittoTag" in order to specify another Ditto version to use for all Ditto services:
# you may also use "1" (for latest Ditto 1.x.x) or "1.5" (for latest Ditto 1.5.x)
# dittoTag: 3.3.0


## ----------------------------------------------------------------------------
## policies configuration
##  ref: https://www.eclipse.dev/ditto/architecture-services-policies.html
policies:
  # enabled controls whether policies related resources should be created
  enabled: true
  # replicaCount configuration for policies
  replicaCount: 1
  # updateStrategy configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
  #  of its containers crashing, for it to be considered available
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
  minReadySeconds: 10
  # additionalLabels configuration for policies
  additionalLabels: {}
  # additionalAnnotations configuration for policies
  additionalAnnotations: {}
  image:
    # repository for the policies docker image
    repository: docker.io/eclipse/ditto-policies
    # tag for the policies docker image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the policies docker image
    pullPolicy: IfNotPresent
  # additionalJvmOptions JVM options to put into JAVA_TOOL_OPTIONS
  additionalJvmOptions: ""
  # systemProps used to define arbitrary system properties for policies service
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#configuration
  systemProps:
  # extraEnv to add arbitrary environment variable to policies container
  extraEnv:
  # - name: LOG_LEVEL_APPLICATION
  #   value: "DEBUG"
  extraVolumes:
  #  - name: policies-extension
  #    configMap:
  #      name: policies-extension.jar
  extraVolumeMounts:
  #  - name: policies-extension
  #    mountPath: /opt/ditto/policies-extension.jar
  #    subPath: policies-extension.jar
  # resources configures the resources available/to use for the policies service
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.5
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 1024
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 2048
  # jvm contains JVM specific scaling/tuning configuration of e.g. processors and garbage collector settings
  jvm:
    # activeProcessorCount defines how many processors the JVM should be configured to use
    #  this is e.g. relevant for the GC which calculates the amount of asynchronous threads for GC based on the processor count
    activeProcessorCount: 2
    # heapRamPercentage defines how much memory of the configured "resources.memoryMi" can be used by the JVM heap space
    #  be aware that the JVM also requires memory for "off heap" (and also stack) space + the container needs memory as well
    heapRamPercentage: 60
    # maxGcPauseMillis configures the used G1 GC "target for the maximum GC pause time"
    #  default (by JVM if not set): 200
    maxGcPauseMillis: 200
    # g1ReservePercent configures the used G1 GC "amount of heap to keep free after a mixed GC"
    #  default (by JVM if not set): 10
    g1ReservePercent: 10
  # startupProbe configuration for policies
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  startupProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 30
  # readinessProbe configuration for policies
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe:
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 6
  # livenessProbe configuration for policies
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  # podDisruptionBudget configuration for policies
  #  ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether policies related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for policies
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podMonitor configuration for policies
  podMonitor:
    # enabled configures whether Pod Monitor is enabled, then a resource to scrape policies metrics will be created
    enabled: false
    # interval: 30s
    # scrapeTimeout: 15s
  # config holds policies specific configuration
  config:
    # mongodb holds mongodb specific configuration of policies
    mongodb:
      # minPoolSize configures the minimum number of connections in the connection pool
      minPoolSize: 10
      # maxPoolSize configures the minimum number of connections in the connection pool
      maxPoolSize: 200
      # maxPoolIdleTime configures the maximum amount of time a pooled connection is allowed to idle before closing the connection
      maxPoolIdleTime: 10m
      # journalWriteConcern the MongoDB write concern to apply for writing operations on the event journal
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      journalWriteConcern: "Journaled"
      # snapsWriteConcern the MongoDB write concern to apply for writing operations on the snapshots persistence
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      snapsWriteConcern: "Journaled"
      # journalCircuitBreaker configures the circuit breaker for MongoDB operations on the event journal
      journalCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting an event occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 10s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 5s
      # snapsCircuitBreaker configures the circuit breaker for MongoDB operations on the snapshots persistence
      snapsCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting a snapshot occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 20s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 8s
    # cleanup contains the configuration for the background cleanup of stale snapshots and events
    cleanup:
      # enabled configures whether background cleanup is enabled or not
      #  if enabled, stale "snapshot" and "journal" entries will be cleaned up from the MongoDB by a background process:
      enabled: true
      # quietPeriod defines how long to stay in a state where the background cleanup is not yet started
      quietPeriod: 5m
      # history contains configuration regarding the event history
      history:
        # retentionDuration configures the duration of how long to "keep" events and snapshots before being allowed to remove them in scope of cleanup
        retentionDuration: 30d
      # metricsReporter config of MongoMetricsReporter which is used by policies in order to report current persistence
      #  roundtrip times in order to determine credits to cleanup stale data (journal entries, snapshots)
      metricsReporter:
        # resolution configures how far apart each measurement should be done
        resolution: 1s
        # history configures how many historical items to keep
        history: 5
      # interval configures how often a "credit decision" is made
      interval: 1s
      # timerThreshold configures the maximum database latency to give out credit for cleanup actions
      timerThreshold: 100ms
      # creditsPerBatch configures how many "cleanup credits" should be generated per "interval" as long as the
      #  write operations to the MongoDB are less than the configured `timerThreshold`.
      #  Limits the rate of cleanup actions to this many per credit decision interval.
      #  One credit means that the "journal" and "snapshot" entries of one entity are cleaned up each `interval`.
      creditsPerBatch: 5
      # readsPerQuery configures the number of snapshots to scan per MongoDB query.
      #  Configuring this to high values will reduce the need to query MongoDB too often - it should however be aligned
      #  with the amount of `creditsPerBatch` issued per `interval` - in order to avoid long running queries.
      readsPerQuery: 100
      # writesPerCredit configures the number of documents to delete for each credit.
      #  If for example one entity would have 1000 journal entries to cleanup, a `writes-per-credit` of 100 would lead
      #  to 10 delete operations performed against MongoDB.
      writesPerCredit: 100
      # deleteFinalDeletedSnapshot configures whether for a deleted entity, the final snapshot (containing the
      #  "deleted" information) should be deleted or not.
      #  If the final snapshot is not deleted, re-creating the entity will cause that the recreated entity starts with
      #  a revision number 1 higher than the previously deleted entity. If the final snapshot is deleted as well,
      #  recreation of an entity with the same ID will lead to revisionNumber=1 after its recreation.
      deleteFinalDeletedSnapshot: true
    # readJournal holds configuration regarding the MongoReadJournal and e.g. the aggregation queries which are performed in it
    readJournal:
      # indexes contains configuration about additional indexes to create
      indexes:
        # createSnapshotAggregationIndexPidId whether to create the "pid"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidId: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSn: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSnId: false
      # hints contains hint names to configure for different aggregation calls done in MongoReadJournal
      hints:
        # filterPidsThatDoesntContainTagInNewestEntry contains the hint name to use in the aggregation query
        filterPidsThatDoesntContainTagInNewestEntry: null
        # listLatestJournalEntries contains the hint name to use in the aggregation query
        listLatestJournalEntries: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains both "pid" and "_id"
        listNewestActiveSnapshotsByBatchPidId: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "pid"
        listNewestActiveSnapshotsByBatchPid: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "_id"
        listNewestActiveSnapshotsByBatchId: null
    # persistence holds configuration regarding (pekko) persistence of policies (event journal and snapshots)
    persistence:
      # activityCheckInterval configures to keep policies for that amount of time in memory when no other use did happen:
      activityCheckInterval: 2d
      # pingRate used to throttle pinging of PolicyPersistenceActors, so that not all PolicyPersistenceActors are recovered at the same time:
      pingRate:
        # frequency the frequency of sent "pings" to PolicyPersistenceActors
        frequency: 1s
        # entities the amount of entities to wake up per "frequency" interval
        entities: 50
      # events contains event journal specific configuration
      events:
        # historicalHeadersToPersist define the DittoHeaders to persist when persisting events to the journal
        # those can e.g. be retrieved as additional "audit log" information when accessing a historical Policy revision
        historicalHeadersToPersist:
        # - "ditto-originator"
        # - "ditto-origin"
        # - "correlation-id"
      # snapshots contains snapshots persistence specific configuration
      snapshots:
        # interval configures the interval when to do snapshot for a Policy which had changes to it
        interval: 15m
        # threshold configures the threshold after how many changes to a Policy to do a snapshot
        threshold: 5
    # entityCreation by default, Ditto allows anyone to create a new entity (policy in this case) in any namespace.
    #  However, this behavior can be customized, and the ability to create new entities can be restricted:
    entityCreation:
      # grants contains the list of creation config entries which would allow the creation of entities
      #  An empty list would *not* allow any entity to be created.
      #  You must have at least one entry, even if it is without restrictions.
      grants:
        -  # namespaces holds the list of namespaces this entry applies to. An empty list would match any.
          #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported in entries of this list.
          namespaces: []
           # authSubjects holds list of authentication subjects this entry applies to. An empty list would match any.
           #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported in entries of this list.
          authSubjects: []
      # revokes contains the list of creation config entries which would reject the creation of entities
      revokes: []
      # - namespaces: []
      #   authSubjects: []
    # policiesEnforcer contains configuration for Ditto "Policy Enforcers", e.g. regarding caching
    policiesEnforcer:
      # cache holds the configuration of policy enforcer caching
      cache:
        # enabled whether caching of policy enforcers should be enabled
        enabled: true
        # maxSize the maximum size of policy enforcers to keep in the cache
        maxSize: 1000
        # expireAfterWrite the maximum duration of inconsistency after losing a cache invalidation
        expireAfterWrite: 4h
        # expireAfterAccess prolonged on each cache access by that duration
        expireAfterAccess: 2h

## ----------------------------------------------------------------------------
## things configuration
##  ref: https://www.eclipse.dev/ditto/architecture-services-things.html
things:
  # enabled controls whether things related resources should be created
  enabled: true
  # replicaCount configuration for things
  replicaCount: 1
  # updateStrategy configuration for things
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
  #  of its containers crashing, for it to be considered available
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
  minReadySeconds: 10
  # additionalLabels configuration for things
  additionalLabels: {}
  # additionalAnnotations configuration for things
  additionalAnnotations: {}
  image:
    # repository for the things docker image
    repository: docker.io/eclipse/ditto-things
    # tag for the things docker image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the things docker image
    pullPolicy: IfNotPresent
  # additionalJvmOptions JVM options to put into JAVA_TOOL_OPTIONS
  additionalJvmOptions: ""
  # systemProps used to define arbitrary system properties for things service
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#configuration
  systemProps:
  # extraEnv to add arbitrary environment variable to things container
  extraEnv:
  # - name: LOG_LEVEL_APPLICATION
  #   value: "DEBUG"
  extraVolumes:
  #  - name: things-extension
  #    configMap:
  #      name: things-extension.jar
  extraVolumeMounts:
  #  - name: things-extension
  #    mountPath: /opt/ditto/things-extension.jar
  #    subPath: things-extension.jar
  # resources configures the resources available/to use for the things service
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.5
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 1024
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 2048
  # jvm contains JVM specific scaling/tuning configuration of e.g. processors and garbage collector settings
  jvm:
    # activeProcessorCount defines how many processors the JVM should be configured to use
    #  this is e.g. relevant for the GC which calculates the amount of asynchronous threads for GC based on the processor count
    activeProcessorCount: 2
    # heapRamPercentage defines how much memory of the configured "resources.memoryMi" can be used by the JVM heap space
    #  be aware that the JVM also requires memory for "off heap" (and also stack) space + the container needs memory as well
    heapRamPercentage: 60
    # maxGcPauseMillis configures the used G1 GC "target for the maximum GC pause time"
    #  default (by JVM if not set): 200
    maxGcPauseMillis: 200
    # g1ReservePercent configures the used G1 GC "amount of heap to keep free after a mixed GC"
    #  default (by JVM if not set): 10
    g1ReservePercent: 10
  # startupProbe configuration for things
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  startupProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 30
  # readinessProbe configuration for things
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe:
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 6
  # livenessProbe configuration for things
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  # podDisruptionBudget configuration for things
  #  ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether things related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for things
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for things
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for things
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for things
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podMonitor configuration for things
  podMonitor:
    # enabled configures whether Pod Monitor is enabled, then a resource to scrape things metrics will be created
    enabled: false
    # interval: 30s
    # scrapeTimeout: 15s
  # config holds things specific configuration
  config:
    # mongodb holds mongodb specific configuration of things
    mongodb:
      # minPoolSize configures the minimum number of connections in the connection pool
      minPoolSize: 10
      # maxPoolSize configures the minimum number of connections in the connection pool
      maxPoolSize: 200
      # maxPoolIdleTime configures the maximum amount of time a pooled connection is allowed to idle before closing the connection
      maxPoolIdleTime: 10m
      # journalWriteConcern the MongoDB write concern to apply for writing operations on the event journal
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      journalWriteConcern: "Acknowledged"
      # snapsWriteConcern the MongoDB write concern to apply for writing operations on the snapshots persistence
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      snapsWriteConcern: "Acknowledged"
      # journalCircuitBreaker configures the circuit breaker for MongoDB operations on the event journal
      journalCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting an event occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 10s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 5s
      # snapsCircuitBreaker configures the circuit breaker for MongoDB operations on the snapshots persistence
      snapsCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting a snapshot occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 20s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 8s
    # cleanup contains the configuration for the background cleanup of stale snapshots and events
    cleanup:
      # enabled configures whether background cleanup is enabled or not
      #  if enabled, stale "snapshot" and "journal" entries will be cleaned up from the MongoDB by a background process:
      enabled: true
      # quietPeriod defines how long to stay in a state where the background cleanup is not yet started
      quietPeriod: 5m
      # history contains configuration regarding the event history
      history:
        # retentionDuration configures the duration of how long to "keep" events and snapshots before being allowed to remove them in scope of cleanup
        retentionDuration: 30d
      # metricsReporter config of MongoMetricsReporter which is used by policies in order to report current persistence
      #  roundtrip times in order to determine credits to cleanup stale data (journal entries, snapshots)
      metricsReporter:
        # resolution configures how far apart each measurement should be done
        resolution: 1s
        # history configures how many historical items to keep
        history: 5
      # interval configures how often a "credit decision" is made
      interval: 1s
      # timerThreshold configures the maximum database latency to give out credit for cleanup actions
      timerThreshold: 100ms
      # creditsPerBatch configures how many "cleanup credits" should be generated per "interval" as long as the
      #  write operations to the MongoDB are less than the configured `timerThreshold`.
      #  Limits the rate of cleanup actions to this many per credit decision interval.
      #  One credit means that the "journal" and "snapshot" entries of one entity are cleaned up each `interval`.
      creditsPerBatch: 5
      # readsPerQuery configures the number of snapshots to scan per MongoDB query.
      #  Configuring this to high values will reduce the need to query MongoDB too often - it should however be aligned
      #  with the amount of `creditsPerBatch` issued per `interval` - in order to avoid long running queries.
      readsPerQuery: 100
      # writesPerCredit configures the number of documents to delete for each credit.
      #  If for example one entity would have 1000 journal entries to cleanup, a `writes-per-credit` of 100 would lead
      #  to 10 delete operations performed against MongoDB.
      writesPerCredit: 100
      # deleteFinalDeletedSnapshot configures whether for a deleted entity, the final snapshot (containing the
      #  "deleted" information) should be deleted or not.
      #  If the final snapshot is not deleted, re-creating the entity will cause that the recreated entity starts with
      #  a revision number 1 higher than the previously deleted entity. If the final snapshot is deleted as well,
      #  recreation of an entity with the same ID will lead to revisionNumber=1 after its recreation.
      deleteFinalDeletedSnapshot: true
    # readJournal holds configuration regarding the MongoReadJournal and e.g. the aggregation queries which are performed in it
    readJournal:
      # indexes contains configuration about additional indexes to create
      indexes:
        # createSnapshotAggregationIndexPidId whether to create the "pid"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidId: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSn: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSnId: false
      # hints contains hint names to configure for different aggregation calls done in MongoReadJournal
      hints:
        # filterPidsThatDoesntContainTagInNewestEntry contains the hint name to use in the aggregation query
        filterPidsThatDoesntContainTagInNewestEntry: null
        # listLatestJournalEntries contains the hint name to use in the aggregation query
        listLatestJournalEntries: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains both "pid" and "_id"
        listNewestActiveSnapshotsByBatchPidId: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "pid"
        listNewestActiveSnapshotsByBatchPid: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "_id"
        listNewestActiveSnapshotsByBatchId: null
    # persistence holds configuration regarding (pekko) persistence of things (event journal and snapshots)
    persistence:
      # activityCheckInterval configures to keep things for that amount of time in memory when no other use did happen
      activityCheckInterval: 2d
      # events contains event journal specific configuration
      events:
        # historicalHeadersToPersist define the DittoHeaders to persist when persisting events to the journal
        #  those can e.g. be retrieved as additional "audit log" information when accessing a historical Thing revision
        historicalHeadersToPersist:
        # - "ditto-originator"
        # - "ditto-origin"
        # - "correlation-id"
      # snapshots contains snapshots persistence specific configuration
      snapshots:
        # the interval when to do snapshot for a Thing which had changes to it
        interval: 15m
        # the threshold after how many changes to a Thing to do a snapshot
        threshold: 50
    # event contains configuration related to e.g. publishing of thing events
    event:
      # preDefinedExtraFields contains pre-defined (configured) extraFields to send along all thing (change) events
      preDefinedExtraFields: []
      # - namespaces:
      #     - "org.eclipse.ditto*"
      #   condition: "eq(attributes/foo,'RQL condition')"
      #   extraFields:
      #     - "definition"
      #     - "attributes/serial"
    # message contains configuration related to distributing thing messages
    message:
      # preDefinedExtraFields contains pre-defined (configured) extraFields to send along all thing messages
      preDefinedExtraFields: []
      # - namespaces:
      #     - "namespace1"
      #     - "namespace2"
      #   condition: "eq(attributes/foo,'RQL condition')"
      #   extra-fields:
      #     - "definition"
      #     - "attributes/serial"
    # entityCreation by default, Ditto allows anyone to create a new entity (thing in this case) in any namespace.
    #  However, this behavior can be customized, and the ability to create new entities can be restricted:
    entityCreation:
      # grants contains the list of creation config entries which would allow the creation of entities
      #  An empty list would *not* allow any entity to be created.
      #  You must have at least one entry, even if it is without restrictions.
      grants:
        -  # namespaces holds the list of namespaces this entry applies to. An empty list would match any.
          #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported in entries of this list.
          namespaces: []
          # authSubjects holds list of authentication subjects this entry applies to. An empty list would match any.
          #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported in entries of this list.
          authSubjects: []
          # thingDefinitions holds list of thing definitions this entry applies to. An empty list would match any.
          #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported in entries of this list.
          #  If the list contains `null`, creation of things without a thing definition is allowed.
          thingDefinitions: []
      # revokes contains the list of creation config entries which would reject the creation of entities
      revokes: []
      # - namespaces: []
      #   authSubjects: []
      #   thingDefinitions: []
    # policiesEnforcer contains configuration for Ditto "Policy Enforcers", e.g. regarding caching
    policiesEnforcer:
      # cache holds the configuration of policy enforcer caching
      cache:
        # enabled whether caching of policy enforcers should be enabled
        enabled: true
        # maxSize the maximum size of policy enforcers to keep in the cache
        maxSize: 2000
        # expireAfterWrite the maximum duration of inconsistency after losing a cache invalidation
        expireAfterWrite: 4h
        # expireAfterAccess prolonged on each cache access by that duration
        expireAfterAccess: 2h
    # merge contains configuration for merge operations with patch conditions
    merge:
      # removeEmptyObjectsAfterPatchConditionFiltering controls whether to remove empty JSON objects from merge payloads when patch conditions filter out all content.
      # When enabled, empty objects created by patch condition filtering will be removed recursively,
      # preventing unnecessary database operations for empty merge payloads.
      removeEmptyObjectsAfterPatchConditionFiltering: false
    # wot contains Web of Things (WoT) specific configuration
    wot:
      # tdBasePrefix is the base to use where the Ditto endpoint is located in order to be injected into TDs:
      tdBasePrefix: "http://localhost:8080"
      # cache contains the configuration for the things model cache
      cache:
        # modelCacheSize configures the amount of TMs to hold in the cache
        modelCacheSize: 1000
        # expireAfterWrite configures how long a single TM should remain cached after first writing it to the cache
        expireAfterWrite: 2d
        # expireAfterAccess configures how long a single TM should remain cached after its last access
        expireAfterAccess: 1d
      # tdJsonTemplate contains a json template added to generated TDs, e.g. containing security information:
      tdJsonTemplate: >-
        {
          "securityDefinitions": {
            "basic_sc": {
              "scheme": "basic",
              "in": "header"
            }
          },
          "security": "basic_sc",
          "support": "https://www.eclipse.dev/ditto/"
        }
      # tmValidation provides configuration settings for WoT (Web of Things) integration regarding the validation of
      #  Things and Features based on their WoT ThingModels
      tmValidation:
        # enabled whether the ThingModel validation of Things/Features should be enabled
        enabled: true
        # log-warning-instead-of-failing-api-calls whether to instead of to reject/fail API calls (when enabled=true), log a WARNING log instead
        log-warning-instead-of-failing-api-calls: false
        # json-schema-cache-enabled whether to enable caching of JSON schemas created from WoT ThingModels
        json-schema-cache-enabled: true
        # jsonSchemaCache configuration of the JSON schema cache
        jsonSchemaCache:
          # maxSize the maximum size of JSON schemas to keep in the cache
          maxSize: 10000
          # expireAfterWrite the maximum duration of inconsistency after losing a cache invalidation
          expireAfterWrite: 12h
          # expireAfterAccess prolonged on each cache access by that duration
          expireAfterAccess: 2h
        # thing provides configuration settings for WoT based validation of Things
        thing:
          # enforce holds all configuration relating to enforcing the model
          enforce:
            # thing-description-modification whether to enforce/validate a thing whenever its description is modified
            thing-description-modification: true
            # attributes whether to enforce/validate attributes of a thing following the defined WoT properties
            attributes: true
            # inbox-messages-input whether to enforce/validate inbox messages to a thing following the defined WoT action "input"
            inbox-messages-input: true
            # inbox-messages-output whether to enforce/validate inbox message responses to a thing following the defined WoT action "output"
            inbox-messages-output: true
            # outbox-messages whether to enforce/validate outbox messages from a thing following the defined WoT event "data"
            outbox-messages: true
          # forbid holds all configuration relating to forbidding/preventing certain interactions
          forbid:
            # thing-description-deletion whether to forbid deletion of a thing's description
            thing-description-deletion: true
            # non-modeled-attributes whether to forbid persisting attributes which are not defined as properties in the WoT model
            non-modeled-attributes: true
            # non-modeled-inbox-messages whether to forbid dispatching of inbox messages which are not defined as actions in the WoT model
            non-modeled-inbox-messages: true
            # non-modeled-outbox-messages whether to forbid dispatching of outbox messages which are not defined as events in the WoT model
            non-modeled-outbox-messages: true
        # feature provides configuration settings for WoT based validation of Features
        feature:
          # enforce holds all configuration relating to enforcing the model
          enforce:
            # feature-description-modification whether to enforce/validate a feature whenever its description is modified
            feature-description-modification: true
            # presence-of-modeled-features whether to enforce that all modeled features
            #  (submodels referenced in the thing's definition's WoT model) are present
            presence-of-modeled-features: true
            # properties whether to enforce/validate properties of a feature following the defined WoT properties
            properties: true
            # desired-properties whether to enforce/validate desired properties of a feature following the defined WoT properties
            desired-properties: true
            # inbox-messages-input whether to enforce/validate inbox messages to a feature following the defined WoT action "input"
            inbox-messages-input: true
            # inbox-messages-output whether to enforce/validate inbox message responses to a feature following the defined WoT action "output"
            inbox-messages-output: true
            # outbox-messages whether to enforce/validate outbox messages from a feature following the defined WoT events
            outbox-messages: true
          # forbid holds all configuration relating to forbidding/preventing certain interactions
          forbid:
            # feature-description-deletion whether to forbid deletion of a feature's description
            feature-description-deletion: true
            # non-modeled-features whether to forbid adding features to a Thing which were not defined in its definition's WoT model
            non-modeled-features: true
            # non-modeled-properties whether to forbid persisting properties which are not defined as properties in the WoT model
            non-modeled-properties: true
            # non-modeled-desired-properties whether to forbid persisting desired properties which are not defined as properties in the WoT model
            non-modeled-desired-properties: true
            # non-modeled-inbox-messages  whether to forbid dispatching of inbox messages which are not defined as actions in the WoT model
            non-modeled-inbox-messages: true
            # non-modeled-outbox-messages whether to forbid dispatching of outbox messages which are not defined as events in the WoT model
            non-modeled-outbox-messages: true
        # dynamicConfig contains an optional array of objects defining `configOverrides` applied when the defined `validationContext` matches an API call
        dynamicConfig: [
          # - validationContext:
          #     # all 3 "patterns" conditions have to match (AND)
          #     dittoHeadersPatterns: # if any (OR) of the contained headers block match
          #       # inside the object, all patterns have to match (AND)
          #       - ditto-originator: "connection:one"
          #     thingDefinitionPatterns: # if any (OR) of the contained patterns match
          #       - "^foo.*bar$"
          #     featureDefinitionPatterns: [ ] # if any (OR) of the contained patterns match
          #   # if the validation-context "matches" a processed API call, apply the following overrides:
          #   configOverrides:
          #     # exactly the same config keys and structure applies as in the static config
          #     enabled: true
          #     log-warning-instead-of-failing-api-calls: true
          #     thing:
          #       enforce:
          #         thing-description-modification: false
          #         attributes: true
          #       forbid:
          #         thing-description-deletion: false
          #     feature:
          #       enforce:
          #         feature-description-modification: false
        ]

## ----------------------------------------------------------------------------
## things-search configuration
##  ref: https://www.eclipse.dev/ditto/architecture-services-things-search.html
thingsSearch:
  # enabled controls whether things-search related resources should be created
  enabled: true
  # replicaCount configuration for things-search
  replicaCount: 1
  # updateStrategy configuration for things-search
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
  #  of its containers crashing, for it to be considered available
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
  minReadySeconds: 10
  # additionalLabels configuration for things-search
  additionalLabels: {}
  # additionalAnnotations configuration for things-search
  additionalAnnotations: {}
  image:
    # repository for the things-search docker image
    repository: docker.io/eclipse/ditto-things-search
    # tag for the things-search docker image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the things-search docker image
    pullPolicy: IfNotPresent
  # additional JVM options to put into JAVA_TOOL_OPTIONS
  additionalJvmOptions: ""
  # systemProps used to define arbitrary system properties for things-search service
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#configuration
  systemProps:
  # extraEnv to add arbitrary environment variable to things-search container
  extraEnv:
  # - name: LOG_LEVEL_APPLICATION
  #   value: "DEBUG"
  extraVolumes:
  #  - name: search-extension
  #    configMap:
  #      name: search-extension.jar
  extraVolumeMounts:
  #  - name: search-extension
  #    mountPath: /opt/ditto/search-extension.jar
  #    subPath: search-extension.jar
  # resources configures the resources available/to use for the things search service
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.5
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 1024
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 2048
  # jvm contains JVM specific scaling/tuning configuration of e.g. processors and garbage collector settings
  jvm:
    # activeProcessorCount defines how many processors the JVM should be configured to use
    #  this is e.g. relevant for the GC which calculates the amount of asynchronous threads for GC based on the processor count
    activeProcessorCount: 2
    # heapRamPercentage defines how much memory of the configured "resources.memoryMi" can be used by the JVM heap space
    #  be aware that the JVM also requires memory for "off heap" (and also stack) space + the container needs memory as well
    heapRamPercentage: 60
    # maxGcPauseMillis configures the used G1 GC "target for the maximum GC pause time"
    #  default (by JVM if not set): 200
    maxGcPauseMillis: 200
    # g1ReservePercent configures the used G1 GC "amount of heap to keep free after a mixed GC"
    #  default (by JVM if not set): 10
    g1ReservePercent: 10
  # startupProbe configuration for policies
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  startupProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 30
  # readinessProbe configuration for things-search
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe:
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 6
  # livenessProbe configuration for things-search
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  # podDisruptionBudget configuration for things-search
  #  ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether things-search related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for things-search
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for things-search
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for things-search
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for things-search
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podMonitor configuration for things-search
  podMonitor:
    # enabled configures whether Pod Monitor is enabled, then a resource to scrape things search metrics will be created
    enabled: false
    # interval: 30s
    # scrapeTimeout: 15s
  # config holds things-search specific configuration
  config:
    # mongodb holds mongodb specific configuration of things-search
    mongodb:
      # maxQueryTime configures MONGO_DB_QUERY_TIMEOUT - by default 60s
      maxQueryTime: 60s
      # minPoolSize configures the minimum number of connections in the connection pool
      minPoolSize: 10
      # maxPoolSize configures the minimum number of connections in the connection pool
      maxPoolSize: 100
      # maxPoolIdleTime configures the maximum amount of time a pooled connection is allowed to idle before closing the connection
      maxPoolIdleTime: 10m
      # searchReadPreference configures the overall MongoDB read preference
      #  one of: primary | primaryPreferred | secondary | secondaryPreferred | nearest
      searchReadPreference: "primary"
      # searchWriteConcern configures the overall MongoDB write concern
      #  one of: unacknowledged | acknowledged | majority | journaled | w1 | w2 | w3
      searchWriteConcern: "acknowledged"
      # searchWithAcksWriteConcern configures the MongoDB write concern for commands sent with "search-persisted" ACK
      #  ref: https://www.eclipse.dev/ditto/basic-acknowledgements.html#built-in-acknowledgement-labels
      #  one of: unacknowledged | acknowledged | majority | journaled | w1 | w2 | w3
      searchWithAcksWriteConcern: "majority"
      # queryReadConcern configures the MongoDB read concern for doing queries / performing searches
      #  only if this is "linearizable" in combination with the searchWithAcksWriteConcern: "majority" a strong consistency
      #  if used in a replicated MongoDB setup, this should be changed to `queryReadConcern: "linearizable"`
      #  for commands using the "search-persisted" requested ACK is guaranteed
      #  one of: default | local | majority | linearizable | snapshot | available
      queryReadConcern: "local"
      # updaterPersistenceReadConcern configures the MongoDB read concern for the "ThingUpdater"
      #  one of: default | local | majority | linearizable | snapshot | available
      updaterPersistenceReadConcern: "local"
      # updaterPersistenceReadPreference configures the MongoDB read preference for the "ThingUpdater"
      updaterPersistenceReadPreference: "primaryPreferred"
      # policyModificationCausedSearchIndexUpdateThrottling contains throttling configuration for the search Index update after a policy update
      policyModificationCausedSearchIndexUpdateThrottling:
        # enabled defines whether throttling should be applied for search Index update after a policy update
        enabled: true
        # interval defined the time window within which the throttling limit applies
        interval: 1s
        # limit is the maximum number of updates allowed within each throttling interval
        limit: 100
    # updater contains configuration for the "Things Updater" of things-search service
    updater:
      # activityCheckInterval configures to keep thing updaters for that amount of time in memory when no update did happen:
      activityCheckInterval: 2h
      # stream contains streaming configuration settings of the things-search service
      stream:
        # retrievalParallelism configures the upper bound of parallel SudoRetrieveThing commands
        #  (by extension, parallel loads of policy enforcer cache)
        retrievalParallelism: 64
        persistence:
          # parallelism configures how much bulk writes to request in parallel - must be a power of 2
          parallelism: 16
        # policiesEnforcer contains configuration for Ditto "Policy Enforcers", e.g. regarding caching
        policiesEnforcer:
          # cache holds the configuration of policy enforcer caching
          cache:
            # maxSize the maximum size of policy enforcers to keep in the cache
            maxSize: 30000
            # expireAfterWrite the maximum duration of inconsistency after losing a cache invalidation
            expireAfterWrite: 12h
            # expireAfterAccess prolonged on each cache access by that duration
            expireAfterAccess: 6h
        # thingCache configures the cache configuration for caching of things in things-search
        thingCache:
          # maxSize defines how many things to cache
          maxSize: 3000
          # expireAfterWrite defines how long at most to keep things in the cache after loading them into the cache
          expireAfterWrite: 12h
          # expireAfterWrite defines how long at most to keep things in the cache after last accessing them from the cache
          expireAfterAccess: 6h
      # backgroundSync contains the configuration for the "background sync" responsible for continuously streaming
      #  over snapshot entries of things to ensure the eventual consistency of the search index
      backgroundSync:
        # enabled whether background sync is turned on
        enabled: true
        # quietPeriod the duration between service start-up and the beginning of background sync
        quietPeriod: 5m
        # idleTimeout how soon to close the remote stream if no element passed through it
        idleTimeout: 5m
        # toleranceWindow how long to wait before reacting to out-of-date search index entries
        toleranceWindow: 20m
        # keepEvents how many events to keep in the actor state
        keepEvents: 2
        # throttle contains the background sync throttling configuration
        throttle:
          # throughput how many things to update per throttle period
          throughput: 100
          # period the throttle period
          period: 30s
    # countHintIndexName contains the optional index name to use for doing count queries at the search collection,
    #  e.g. preventing use of the wildcard index
    countHintIndexName: null
    # indexInitialization contains configuration for creation of the "search" collection indices
    indexInitialization:
      # enabled whether the index initialization should be enabled or not (also removes not known indices)
      enabled: true
      # activatedIndexNames contains the list of indices to be actively created (well known ones) or custom ones not to remove actively
      #  if the list is empty, all "Ditto known" indices will be created
      activatedIndexNames: []
        # - "_namespace",
        # - "global_read",
        # - "v_wildcard",
        # - "v_wildcard_id",
        # - "policyId",
        # - "referencedPolicies",
        # - "deleteAt"
    # indexedFieldsLimiting by default, Ditto indexed all fields of things in its search.
    #  However, this behavior can be customized, providing configuration to only index certain fields for specified namespaces.
    indexedFieldsLimiting:
      # enabled whether field index limiting should be enabled or not
      enabled: false
      # items contains the list of per-namespace configuration of which fields to include into to the search index
      items:
      #  - # namespacePattern holds the namespace for which the single limiting configuration entry should apply.
      #    #  Wildcards `*` (Matching any number of any character) and `?` (Matches any single character) are supported.
      #    namespacePattern: "org.eclipse.*"
      #    # indexedFields holds a list of fields that will be explicitly included in the search index
      #    indexedFields:
      #      - "attributes"
      #      - "features/included"
    # operatorMetrics contains configuration for operator defined custom metrics, using a search "count" with namespaces and filter
    operatorMetrics:
      # enabled configures whether operator metrics should be enabled or not
      enabled: true
      # scrapeInterval defines the default scrape interval if a "customMetric" did not specify a custom scrape interval
      scrapeInterval: 15m
      # customMetrics holds a map of metric-names as key (e.g. "ditto_my_awesome_things") and custom metric config as value
      customMetrics:
      # ditto_my_awesome_things:
      #   enabled: true
      #   scrapeInterval: 5m
      #   namespaces:
      #     - "org.eclipse.ditto"
      #   filter: "eq(attributes/awesome,true)"
      #   tags:
      #     foo: bar
      customAggregationMetrics:
      # ditto_my_agg_awesome_things:
      #   enabled: true
      #   scrapeInterval: 5m
      #   namespaces:
      #     - "org.eclipse.ditto"
      #   groupBy:
      #     "location": "attributes/Info/location"
      #   tags:
      #     "hardcoded-tag": "value"
      #     "location": "{{ group-by:location | fn:default('missing location') }}"
      #   filter: "gt(features/ConnectionStatus/properties/status/readyUntil,time:now)"


## ----------------------------------------------------------------------------
## connectivity configuration
##  ref: https://www.eclipse.dev/ditto/architecture-services-connectivity.html
connectivity:
  # enabled controls whether connectivity related resources should be created
  enabled: true
  # replicaCount configuration for connectivity
  replicaCount: 1
  # updateStrategy configuration for connectivity
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
  #  of its containers crashing, for it to be considered available
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
  minReadySeconds: 10
  # additionalLabels configuration for connectivity
  additionalLabels: {}
  # additionalAnnotations configuration for connectivity
  additionalAnnotations: {}
  image:
    # repository for the connectivity docker image
    repository: docker.io/eclipse/ditto-connectivity
    # tag for the connectivity docker image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the connectivity docker image
    pullPolicy: IfNotPresent
  # additional JVM options to put into JAVA_TOOL_OPTIONS
  additionalJvmOptions: ""
  # systemProps used to define arbitrary system properties for connectivity service
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#configuration
  systemProps:
  # extraEnv to add arbitrary environment variable to connectivity container
  extraEnv:
  # - name: LOG_LEVEL_APPLICATION
  #   value: "DEBUG"
  extraVolumes:
  #  - name: connectivity-extension
  #    configMap:
  #      name: connectivity-extension.jar
  extraVolumeMounts:
  #  - name: connectivity-extension
  #    mountPath: /opt/ditto/connectivity-extension.jar
  #    subPath: connectivity-extension.jar
  # resources configures the resources available/to use for the connectivity service
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.5
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 1024
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 2048
  # jvm contains JVM specific scaling/tuning configuration of e.g. processors and garbage collector settings
  jvm:
    # activeProcessorCount defines how many processors the JVM should be configured to use
    #  this is e.g. relevant for the GC which calculates the amount of asynchronous threads for GC based on the processor count
    activeProcessorCount: 2
    # heapRamPercentage defines how much memory of the configured "resources.memoryMi" can be used by the JVM heap space
    #  be aware that the JVM also requires memory for "off heap" (and also stack) space + the container needs memory as well
    heapRamPercentage: 60
    # maxGcPauseMillis configures the used G1 GC "target for the maximum GC pause time"
    #  default (by JVM if not set): 200
    maxGcPauseMillis: 200
    # g1ReservePercent configures the used G1 GC "amount of heap to keep free after a mixed GC"
    #  default (by JVM if not set): 10
    g1ReservePercent: 10
  # startupProbe configuration for connectivity
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  startupProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 30
  # readinessProbe configuration for connectivity
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe:
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 6
  # livenessProbe configuration for connectivity
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  # podDisruptionBudget configuration for connectivity
  #  ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether connectivity related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for connectivity
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for connectivity
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for connectivity
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for connectivity
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podMonitor configuration for connectivity
  podMonitor:
    # enabled configures whether Pod Monitor is enabled, then a resource to scrape connectivity metrics will be created
    enabled: false
    # interval: 30s
    # scrapeTimeout: 15s
  # config holds connectivity specific configuration
  config:
    # mongodb holds mongodb specific configuration of connectivity
    mongodb:
      # minPoolSize configures the minimum number of connections in the connection pool
      minPoolSize: 10
      # maxPoolSize configures the minimum number of connections in the connection pool
      maxPoolSize: 50
      # maxPoolIdleTime configures the maximum amount of time a pooled connection is allowed to idle before closing the connection
      maxPoolIdleTime: 10m
      # journalWriteConcern the MongoDB write concern to apply for writing operations on the event journal
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      journalWriteConcern: "Journaled"
      # snapsWriteConcern the MongoDB write concern to apply for writing operations on the snapshots persistence
      #  one of: Unacknowledged | Acknowledged | Journaled | ReplicaAcknowledged | W1 | W2 | W3
      #  caution: Acknowledged refers to the MongoDB server's configured "default write concern"
      snapsWriteConcern: "Journaled"
      # journalCircuitBreaker configures the circuit breaker for MongoDB operations on the event journal
      journalCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting an event occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 10s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 5s
      # snapsCircuitBreaker configures the circuit breaker for MongoDB operations on the snapshots persistence
      snapsCircuitBreaker:
        # maxTries opens the circuit breaker if an exception during persisting a snapshot occurs this often
        #  a successful write resets the counter
        maxTries: 10
        # timeout configures the MongoDB write timeouts also causing the circuit breaker to open
        timeout: 20s
        # reset after this time in "Open" state, the circuit breaker is "Half-opened" again
        reset: 8s
    # policiesEnforcer contains configuration for Ditto "Policy Enforcers", e.g. regarding caching
    policiesEnforcer:
      # cache holds the configuration of policy enforcer caching
      cache:
        # enabled whether caching of policy enforcers should be enabled
        enabled: true
        # maxSize the maximum size of policy enforcers to keep in the cache
        maxSize: 1000
        # expireAfterWrite the maximum duration of inconsistency after losing a cache invalidation
        expireAfterWrite: 4h
        # expireAfterAccess prolonged on each cache access by that duration
        expireAfterAccess: 2h
    # signalEnrichment contains configuration regarding signal enrichment (retrieval of "extra" fields to e.g. enrich events)
    signalEnrichment:
      # cache holds the configuration of signal enrichment caching
      cache:
        # enabled whether signal enrichment caching (incl. smart updates updating the cache based on event data) should be enabled
        enabled: true
        # maximumSize how many things to cache in total on a single cluster node
        maximumSize: 2000
        # expireAfterCreate maximum duration of inconsistency after e.g. a policy update
        expireAfterCreate: 2m
    # cleanup contains the configuration for the background cleanup of stale snapshots and events
    cleanup:
      # enabled configures whether background cleanup is enabled or not
      #  if enabled, stale "snapshot" and "journal" entries will be cleaned up from the MongoDB by a background process:
      enabled: true
      # quietPeriod defines how long to stay in a state where the background cleanup is not yet started
      quietPeriod: 5m
      # history contains configuration regarding the event history
      history:
        # retentionDuration configures the duration of how long to "keep" events and snapshots before being allowed to remove them in scope of cleanup
        retentionDuration: 30d
      # metricsReporter config of MongoMetricsReporter which is used by policies in order to report current persistence
      #  roundtrip times in order to determine credits to cleanup stale data (journal entries, snapshots)
      metricsReporter:
        # resolution configures how far apart each measurement should be done
        resolution: 1s
        # history configures how many historical items to keep
        history: 5
      # interval configures how often a "credit decision" is made
      interval: 10s
      # timerThreshold configures the maximum database latency to give out credit for cleanup actions
      timerThreshold: 100ms
      # creditsPerBatch configures how many "cleanup credits" should be generated per "interval" as long as the
      #  write operations to the MongoDB are less than the configured `timerThreshold`.
      #  Limits the rate of cleanup actions to this many per credit decision interval.
      #  One credit means that the "journal" and "snapshot" entries of one entity are cleaned up each `interval`.
      creditsPerBatch: 1
      # readsPerQuery configures the number of snapshots to scan per MongoDB query.
      #  Configuring this to high values will reduce the need to query MongoDB too often - it should however be aligned
      #  with the amount of `creditsPerBatch` issued per `interval` - in order to avoid long running queries.
      readsPerQuery: 100
      # writesPerCredit configures the number of documents to delete for each credit.
      #  If for example one entity would have 1000 journal entries to cleanup, a `writes-per-credit` of 100 would lead
      #  to 10 delete operations performed against MongoDB.
      writesPerCredit: 100
      # deleteFinalDeletedSnapshot configures whether for a deleted entity, the final snapshot (containing the
      #  "deleted" information) should be deleted or not.
      #  If the final snapshot is not deleted, re-creating the entity will cause that the recreated entity starts with
      #  a revision number 1 higher than the previously deleted entity. If the final snapshot is deleted as well,
      #  recreation of an entity with the same ID will lead to revisionNumber=1 after its recreation.
      deleteFinalDeletedSnapshot: true
    # readJournal holds configuration regarding the MongoReadJournal and e.g. the aggregation queries which are performed in it
    readJournal:
      # indexes contains configuration about additional indexes to create
      indexes:
        # createSnapshotAggregationIndexPidId whether to create the "pid"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidId: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSn: false
        # createSnapshotAggregationIndexPidSn whether to create the "pid"+"sn"+"_id" compound index on the snapshot collection
        createSnapshotAggregationIndexPidSnId: false
      # hints contains hint names to configure for different aggregation calls done in MongoReadJournal
      hints:
        # filterPidsThatDoesntContainTagInNewestEntry contains the hint name to use in the aggregation query
        filterPidsThatDoesntContainTagInNewestEntry: null
        # listLatestJournalEntries contains the hint name to use in the aggregation query
        listLatestJournalEntries: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains both "pid" and "_id"
        listNewestActiveSnapshotsByBatchPidId: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "pid"
        listNewestActiveSnapshotsByBatchPid: null
        # listNewestActiveSnapshotsByBatchPidId contains the hint name to use in the aggregation query where the $match contains only "_id"
        listNewestActiveSnapshotsByBatchId: null
    # persistence holds configuration regarding (akka) persistence of connections (event journal and snapshots)
    persistence:
      # keep closed, inactive connections for that amount of time in memory when no other use did happen:
      activityCheckInterval: 45m
      # events contains event journal specific configuration
      events:
        # historicalHeadersToPersist define the DittoHeaders to persist when persisting events to the journal
        # those can e.g. be retrieved as additional "audit log" information when accessing a historical Connection revision
        historicalHeadersToPersist:
        # - "ditto-originator"
        # - "ditto-origin"
        # - "correlation-id"
      # snapshots contains snapshots persistence specific configuration
      snapshots:
        # interval the interval when to do snapshot for a Connection which had changes to it
        interval: 15m
        # threshold the threshold after how many changes to a Connection to do a snapshot
        threshold: 5
    # connections holds configuration regarding connections
    connections:
      # reconnect configures pinging of connections, so that not all connections are recovered at the same time
      reconnect:
        # rate configures the rate in which frequency to ping/wake up how many entities (connections)
        rate:
          # frequency the frequency of how often to wake up connections after restart
          frequency: 1s
          # entities the amount of entities to wake up per "frequency" interval
          entities: 10
      # allowedHostnames contains a comma separated list of explicitly allowed hostnames
      allowedHostnames: ""
      # blockedHostnames contains a comma separated list of blocked hostnames
      blockedHostnames: ""
      # blockedSubnets holds a comma separated string of blocked subnets
      #  specify subnets to block in CIDR format e.g. "11.1.0.0/16"
      blockedSubnets: ""
      # blockedHostRegex contains the regex for blocked hostnames
      blockedHostRegex: ""
      limits:
        # maxSources contains the max number of sources per connection
        maxSources: 5
        # maxTargets contains the max number of targets per connection
        maxTargets: 5
      enrichment:
        # the buffer size used for the queue in the message mapping processor actor
        bufferSize: 2000
      # kafka contains the configuration specific to Ditto connections to Apache Kafka
      kafka:
        # consumer contains configuration for consuming messages from Kafka
        consumer:
          # throttling contains configuration for applying throttling when consuming from a single Kafka connection
          throttling:
            # enabled defines whether throttling should be applied when consuming messages from a Kafka source
            enabled: true
            # interval the interval at which the consumer is throttled - must be > 0s
            interval: 1s
            # limit defines the maximum number of messages the consumer is allowed to receive within the configured
            #  throttling "interval" e.g. 100 msgs/s - must be > 0
            limit: 500
            # maxInflightFactor configures how many unacknowledged messages are allowed at any time as factor of
            #  ${limit} - must be >= 1.0
            #  This limit couples latency with throughput (long latency before ack -> lower throughput)
            maxInflightFactor: 2.0
        # producer contains configuration for publishing messages to Kafka
        producer:
          # If a message can't be published it is put in a queue. Further messages are dropped when the queue is full.
          queueSize: 1000
          # Messages to publish in parallel per Kafka-Publisher (one per connectivity client)
          parallelism: 10

## ----------------------------------------------------------------------------
## gateway configuration
##  ref: https://www.eclipse.dev/ditto/architecture-services-gateway.html
gateway:
  # enabled controls whether gateway related resources should be created
  enabled: true
  # replicaCount configuration for gateway
  replicaCount: 1
  # updateStrategy configuration for gateway
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # minReadySeconds configures the minimum number of seconds for which a newly created Pod should be ready without any
  #  of its containers crashing, for it to be considered available
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#min-ready-seconds
  minReadySeconds: 10
  # additionalLabels configuration for gateway
  additionalLabels: {}
  # additionalAnnotations configuration for gateway
  additionalAnnotations: {}
  # additional JVM options to put into JAVA_TOOL_OPTIONS
  additionalJvmOptions: ""
  image:
    # repository for the gateway docker image
    repository: docker.io/eclipse/ditto-gateway
    # tag for the gateway docker image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the gateway docker image
    pullPolicy: IfNotPresent
  # systemProps used to define arbitrary system properties configuration for gateway
  #  ref: https://www.eclipse.dev/ditto/installation-operating.html#configuration
  systemProps:
    - "-Dditto.protocol.blocklist.0=raw-request-uri"
    - "-Dditto.protocol.blocklist.1=cache-control"
    - "-Dditto.protocol.blocklist.2=connection"
    - "-Dditto.protocol.blocklist.3=timeout-access"
    - "-Dditto.protocol.blocklist.4=accept-encoding"
    - "-Dditto.protocol.blocklist.5=x-forwarded-scheme"
    - "-Dditto.protocol.blocklist.6=x-forwarded-port"
    - "-Dditto.protocol.blocklist.7=x-forwarded-for"
    - "-Dditto.protocol.blocklist.8=forwarded=for"
    - "-Dditto.protocol.blocklist.9=sec-fetch-mode"
    - "-Dditto.protocol.blocklist.10=sec-fetch-site"
    - "-Dditto.protocol.blocklist.11=authorization"
    - "-Dditto.protocol.blocklist.12=accept-language"
    - "-Dditto.protocol.blocklist.13=host"
    - "-Dditto.protocol.blocklist.14=via"
    - "-Dditto.protocol.blocklist.15=sec-ch-ua"
    - "-Dditto.protocol.blocklist.16=sec-ch-ua-mobile"
    - "-Dditto.protocol.blocklist.17=sec-ch-ua-platform"
    - "-Dditto.protocol.blocklist.18=sec-fetch-dest"
    - "-Dditto.protocol.blocklist.19=user-agent"
  # extraEnv to add arbitrary environment variables to gateway container
  extraEnv:
  # - name: LOG_LEVEL_APPLICATION
  #   value: "DEBUG"
  extraVolumes:
  #  - name: gatway-extension
  #    configMap:
  #      name: gatway-extension.jar
  extraVolumeMounts:
  #  - name: gatway-extension
  #    mountPath: /opt/ditto/gatway-extension.jar
  #    subPath: gatway-extension.jar
  # resources configures the resources available/to use for the gateway service
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.5
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 1024
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 2048
  # jvm contains JVM specific scaling/tuning configuration of e.g. processors and garbage collector settings
  jvm:
    # activeProcessorCount defines how many processors the JVM should be configured to use
    #  this is e.g. relevant for the GC which calculates the amount of asynchronous threads for GC based on the processor count
    activeProcessorCount: 2
    # heapRamPercentage defines how much memory of the configured "resources.memoryMi" can be used by the JVM heap space
    #  be aware that the JVM also requires memory for "off heap" (and also stack) space + the container needs memory as well
    heapRamPercentage: 60
    # maxGcPauseMillis configures the used G1 GC "target for the maximum GC pause time"
    #  default (by JVM if not set): 200
    maxGcPauseMillis: 200
    # g1ReservePercent configures the used G1 GC "amount of heap to keep free after a mixed GC"
    #  default (by JVM if not set): 10
    g1ReservePercent: 10
  # startupProbe configuration for gateway
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  startupProbe:
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 30
  # readinessProbe configuration for gateway
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe:
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 6
  # livenessProbe configuration for gateway
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  # service configuration of the k8s service of the gateway
  service:
    # port number configuration for gateway
    port: 8080
    # annotations to add arbitrary annotations to nginx service
    annotations: {}
  # podDisruptionBudget configuration for gateway
  #  ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether gateway related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for gateway
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for gateway
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for gateway
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for gateway
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podMonitor configuration for gateway
  podMonitor:
    # enabled configures whether Pod Monitor is enabled, then a resource to scrape gateway metrics will be created
    enabled: false
    # interval: 30s
    # scrapeTimeout: 15s
  # config holds gateway specific configuration
  config:
    # authentication contains the settings regarding authentication against the gateway
    authentication:
      # enablePreAuthentication whether Ditto "pre-authentication" should be enabled
      #  ref: https://www.eclipse.dev/ditto/installation-operating.html#pre-authentication
      enablePreAuthentication: false
      # oauth contains the OAuth2.0 / OpenID Connect related configuration
      oauth:
        # allowedClockSkew configures the amount of clock skew in seconds to tolerate when verifying the local time against the exp and nbf claims
        allowedClockSkew: 20s
        # openidConnectIssuers holds a map of issuer-prefixes as key (e.g. "example")
        #  and OAuth "issuer" and "authSubjects" list containing which claims to extract from a JWT issued by the issuer
        openidConnectIssuers:
        #  example:
        #    issuer: "example.com"
        #    authSubjects:
        #    - "{{ jwt:sub }}"
        #    - "{{ jwt:groups }}"
        #    injectClaimsIntoHeaders:
        #      user_email: "{{ jwt:email }}"
        #      user_name: "{{ jwt:name }}"
        # configure the subject to inject in policy action activateTokenIntegration
        tokenIntegrationSubject: "integration:{{policy-entry:label}}:{{jwt:aud}}"
      # devops contains the configuration of the gateway's "/devops" API, e.g. access to it
      devops:
        # secured this controls whether "/devops" and "/api/2/connections" resources are secured or not
        secured: true
        # authMethod declares the authentication method to apply for authenticating the "/devops" and "/api/2/connections" resources
        #  one of: "basic" | "oauth2"
        authMethod: "basic"
        # oauth contains the OAuth2.0 / OpenID Connect related configuration applied when "authMethod" above is "oauth2"
        oauth:
          # allowedClockSkew configures the amount of clock skew in seconds to tolerate when verifying the local time against the exp and nbf claims
          allowedClockSkew: 20s
          # openidConnectIssuers holds a map of issuer-prefixes as key (e.g. "example")
          #  and OAuth "issuer" and "authSubjects" list containing which claims to extract from a JWT issued by the issuer
          openidConnectIssuers:
          #  example-ops:
          #    issuer: "example.com"
          #    authSubjects:
          #    - "{{ jwt:sub }}"
          #    - "{{ jwt:groups }}"
          #    injectClaimsIntoHeaders:
          #      user_email: "{{ jwt:email }}"
          #      user_name: "{{ jwt:name }}"
        # oauthSubjects contains list of subjects authorized to use "/devops" and "/api/2/connections" resources
        oauthSubjects:
        # - "example-ops:devops-admin"
        # statusSecured controls whether the "/status" and "/status/health" resources are secured or not
        statusSecured: true
        # statusAuthMethod declares the authentication method to apply for authenticating the "/status" and "/status/health" resources
        #  one of: "basic" | "oauth2"
        statusAuthMethod: "basic"
        # statusOauthSubjects contains list of subjects authorized to use "/status" API
        statusOauthSubjects:
        # - "example-ops:devops-admin"
        # existingSecret contains the name of existing secret containing status and devops passwords
        #  if not set then default secret is created - useful for managing secrets with external secrets manager
        existingSecret:
        # devopsPassword the password to use for accessing "/devops" and "/api/2/connections" resources
        #  when "authMethod": "basic" (with username: devops)
        #  if not set a random password will be generated and used
        devopsPassword:
        # statusPassword will be used for accessing "/status" and "/status/health" resources
        #  when "statusAuthMethod": "basic" (with username: devops)
        #  if not set a random password will be set
        statusPassword:
    # websocket contains the gateway websocket configuration
    websocket:
      # subscriber contains the configuration for receiving data via the websocket
      subscriber:
        # backpressureQueueSize is the max queue size of how many inflight commands a single websocket client can have
        backpressureQueueSize: 100
      # publisher contains the configuration for sending/publishing data via the websocket
      publisher:
        # backpressureBufferSize is the max buffer size of how many outstanding CommandResponses and Events a single
        #  websocket client can have - additional CommandResponses and Events are dropped if this size is reached
        backpressureBufferSize: 200
      # throttling contains the throttling configuration of a single websocket session
      throttling:
        # enabled whether throttling message consumption via a single websocket session is enabled
        enabled: true
        # interval is the interval at which a single websocket session is rate-limited - must be > 0s
        interval: 1s
        # limit is the maximum number of messages the websocket session is allowed to receive within the configured
        #  throttling interval e.g. 100 msgs/s
        limit: 100
    # websocket contains the gateway SSE (server sent events) configuration
    sse:
      # throttling contains the throttling configuration of a single SSE session (only applies for search via SSE)
      throttling:
        # enabled whether throttling message publishing via a single websocket session is enabled
        enabled: true
        # interval is the interval at which a single SSE session is rate-limited - must be > 0s
        interval: 1s
        # limit is the maximum number of messages the SSE session is allowed to receive within the configured
        #  throttling interval e.g. 100 msgs/s
        limit: 100
    # signalEnrichment contains configuration regarding signal enrichment (retrieval of "extra" fields to e.g. enrich events)
    signalEnrichment:
      # cache holds the configuration of signal enrichment caching
      cache:
        # enabled whether signal enrichment caching (incl. smart updates updating the cache based on event data) should be enabled
        enabled: true
        # maximumSize how many things to cache in total on a single cluster node
        maximumSize: 2000
        # expireAfterCreate maximum duration of inconsistency after e.g. a policy update
        expireAfterCreate: 2m

## ----------------------------------------------------------------------------
## nginx configuration
nginx:
  # enabled controls whether nginx related resources should be created
  enabled: true
  # replicaCount for nginx
  replicaCount: 1
  # updateStrategy for nginx
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # additionalLabels on nginx pods
  additionalLabels: {}
  # additionalAnnotations on nginx pods
  additionalAnnotations: {}
  image:
    # repository for the nginx docker image
    repository: public.ecr.aws/nginx/nginx
    # tag for the nginx docker image
    tag: 1.27
    # pullPolicy for the nginx docker image
    pullPolicy: IfNotPresent
  # extraEnv to add arbitrary environment variables to nginx container
  extraEnv: []
  # resources configures the resources available/to use for nginx
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.2
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 64
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 64
  # readinessProbe configuration for nginx
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  readinessProbe: {}
  # livenessProbe configuration for nginx
  #  ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  livenessProbe: {}
  # service configuration of the k8s service of the nginx
  service:
    # type of the nginx service
    type: ClusterIP
    # port of the nginx service
    port: 8080
    # in case of <type> NodePort the <nodePort> may additionally be set
    #  type: NodePort
    #  nodePort: 30080
    # annotations to add arbitrary annotations to nginx service
    annotations: {}
  # priorityClassName configuration for policies
  #  ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
  priorityClassName: ""
  # nodeSelector configuration for nginx
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}
  # tolerations configuration for nginx
  #  ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # affinity configuration for nginx
  #  ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # Pod topology spread constraints for nginx
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # init containers for nginx
  initContainers:
    waitForGateway:
      enabled: true
      name: wait-for-gateway
      image: rancher/curlimages-curl:7.73.0
  # config holds nginx specific configuration
  config:
    # workerProcesses the 'worker_processes' option for nginx to use - can also be set to 'auto' in order to let nginx
    # determine the worker processes based on the CPU count
    workerProcesses: 4
    # workerProcesses the 'events' 'worker_connections' option for nginx to use
    workerConnections: 1024
    # the 'proxy_connect_timeout', 'proxy_send_timeout', 'proxy_read_timeout' and 'send_timeout' options for nginx
    # timeouts are configured slightly higher than ditto-eclipse-ditto-gateway read-timeout
    timeout: 70

## ----------------------------------------------------------------------------
## Ditto UI configuration
dittoui:
  enabled: true
  # replicaCount for Ditto UI service
  replicaCount: 1
  # updateStrategy for Ditto UI service
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # additionalLabels on Ditto UI pods
  additionalLabels: {}
  # additionalAnnotations on Ditto UI pods
  additionalAnnotations: {}
  image:
    # repository for the Ditto UI docker image
    repository: docker.io/eclipse/ditto-ui
    # tag for the Ditto UI image - overwrite to specify something else than Chart.AppVersion
    # tag: 3.3.0
    # pullPolicy for the Ditto UI docker image
    pullPolicy: IfNotPresent
  # extraEnv to add arbitrary environment variable to Ditto UI container
  extraEnv: []
  # resources configures the resources available/to use for the Ditto UI container
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.1
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 64
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 64
  # Pod topology spread constraints for Ditto UI
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podDisruptionBudget ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether Ditto UI related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # service configuration of the k8s service of the Ditto UI
  service:
    # port of the Ditto UI service
    port: 8080
    # annotations to add arbitrary annotations to Ditto UI service
    annotations: {}

## ----------------------------------------------------------------------------
## swaggerui configuration
swaggerui:
  # enabled controls whether swagger ui related resources should be created
  enabled: true
  # replicaCount for swagger ui service
  replicaCount: 1
  # updateStrategy for swagger ui service
  #  ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  # additionalLabels on swagger ui pods
  additionalLabels: {}
  # additionalAnnotations on swagger ui pods
  additionalAnnotations: {}
  image:
    # repository for the swagger ui docker image
    repository: docker.io/swaggerapi/swagger-ui
    # tag for the swagger ui docker image
    tag: v5.29.1
    # pullPolicy for the swagger ui docker image
    pullPolicy: IfNotPresent
  # extraEnv to add arbitrary environment variable to swagger ui container
  extraEnv: []
  # resources configures the resources available/to use for the swagger ui container
  resources:
    # cpu defines the "required" CPU of a node so that the service is placed there
    cpu: 0.1
    # memoryMi defines the memory in mebibyte (MiB) used as "required" and "limit" in k8s
    memoryMi: 64
    # ephemeralStorageMi defines the storage in mebibyte (MiB) used as "required" and "limit" in k8s
    ephemeralStorageMi: 64
  # Pod topology spread constraints for the swagger ui
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
  # podDisruptionBudget ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # enabled controls whether swagger ui related PodDisruptionBudget should be created
    enabled: true
    # minAvailable number of replicas during voluntary disruptions
    minAvailable: 1
    # maxUnavailable number of replicas during voluntary disruptions
    maxUnavailable: 1
  # service configuration of the k8s service of the swagger ui
  service:
    # port of the swagger ui service
    port: 8080
    # annotations to add arbitrary annotations to swagger ui service
    annotations: {}

## ----------------------------------------------------------------------------
## mongodb dependency chart configuration
mongodb:
  # enabled controls whether mongodb should be started as part of the Helm chart or not
  enabled: true
  image:
    repository: bitnamilegacy/mongodb
    tag: "7.0.9"
  # fullnameOverride: ditto-mongodb
  auth:
    enabled: false
  securityContext:
    enabled: false
  persistence:
    enabled: false
