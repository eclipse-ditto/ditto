ditto {
  mapping-strategy.implementation = "org.eclipse.ditto.services.models.thingsearch.ThingSearchMappingStrategy"

  cluster {
    become-leader = false
    instance-index = ${?INSTANCE_INDEX}
  }

  services-utils-config.mongodb {
    options {
      ssl = false
      w = 1
    }

    pool {
      maxSize = 1000
      maxSize = ${?MONGO_DB_CONNECTION_POOL_SIZE}
      maxWaitTime = 30s
      maxWaitTime = ${?MONGO_DB_CONNECTION_POOL_WAIT_TIME}
      maxWaitQueueSize = 1000
      maxWaitQueueSize = ${?MONGO_DB_CONNECTION_POOL_QUEUE_SIZE}
      jmxListenerEnabled = false
      jmxListenerEnabled = ${?MONGO_DB_CONNECTION_POOL_JMX_LISTENER_ENABLED}
    }
  }

  things-search {
    http {
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = ""
      hostname = ${?HOSTNAME}
      hostname = ${?BIND_HOSTNAME}
      port = 8080
      port = ${?HTTP_PORT}
      port = ${?PORT}
    }

    cluster {
      # enables the majority check that solves network partitions automatically
      majority-check.enabled = false
      majority-check.enabled = ${?CLUSTER_MAJORITY_CHECK_ENABLED}

      # the delay after which the cluster majority is checked
      majority-check.delay = 30s
      majority-check.delay = ${?CLUSTER_MAJORITY_CHECK_DELAY}

      # as a rule of thumb: should be factor ten of the amount of cluster nodes available
      # be aware that it must be the same as for all other services (e.g. things)
      number-of-shards = 30
      number-of-shards = ${?CLUSTER_NUMBER_OF_SHARDS}
    }

    mongodb {
      breaker {
        maxFailures = 5 # defines ater how many failures the circuit breaker should open
        maxFailures = ${?BREAKER_MAXFAILURES}
        timeout {
          call = 5s # MongoDB Timeouts causing the circuitBreaker to open - "0s" disables timeouts opening the breaker
          call = ${?BREAKER_TIMEOUT}
          reset = 10s # after this time in "Open" state, the cicuitBreaker is "Half-opened" again
          reset = ${?BREAKER_RESET}
        }
      }
      monitoring {
        commands = true
        commands = ${?MONGODB_MONITORING_COMMANDS_ENABLED}
        connection-pool = true
        commands = ${?MONGODB_MONITORING_CONNECTION_POOL_ENABLED}
      }
    }

    health-check {
      enabled = true
      enabled = ${?HEALTH_CHECK_ENABLED} # may be overridden with this environment variable
      interval = 60s

      persistence {
        enabled = true
        enabled = ${?HEALTH_CHECK_PERSISTENCE_ENABLED} # may be overridden with this environment variable
        timeout = 60s
      }
    }

    index-initialization {
      #indices should be created within this application
      enabled = true
      enabled = ${?INDEX_INITIALIZATION_ENABLED}
    }

    statsd {
      hostname = ${?STATSD_PORT_8125_UDP_ADDR}
      port = ${?STATSD_PORT_8125_UDP_PORT}
    }

    updater {

      max-bulk-size = ${?MAX_BULK_SIZE}

      activity-check-interval = 1m
      activity-check-interval = ${?ACTIVITY_CHECK_INTERVAL}

      event-processing {
        active = true
        active = ${?EVENT_PROCESSING_ACTIVE}
      }

      sync {
        things {
          active = true
          active = ${?THINGS_SYNCHRONIZATION_ACTIVE}
          start-offset = 30m
          start-offset = ${?THINGS_SYNCHRONIZATION_START_OFFSET}
          initial-start-offset = 120m
          initial-start-offset = ${?THINGS_SYNCHRONIZATION_INITIAL_START_OFFSET}
          stream-interval = 5m
          stream-interval = ${?THINGS_SYNCHRONIZATION_STREAM_INTERVAL}
          outdated-warning-offset = 3h
          outdated-warning-offset = ${?THINGS_SYNCHRONIZATION_OUTDATED_WARNING_OFFSET}
          outdated-error-offset = 4h
          outdated-error-offset = ${?THINGS_SYNCHRONIZATION_OUTDATED_ERROR_OFFSET}
          max-idle-time = 1m
          max-idle-time = ${?THINGS_SYNCHRONIZATION_MAX_IDLE_TIME}
          streaming-actor-timeout = 5m
          streaming-actor-timeout = ${?THINGS_SYNCHRONIZATION_STREAMING_ACTOR_TIMEOUT}
          elements-streamed-per-batch = 10
          elements-streamed-per-batch = ${?THINGS_SYNCHRONIZATION_ELEMENTS_PER_SECOND}
        }

        policies {
          active = true
          active = ${?POLICIES_SYNCHRONIZATION_ACTIVE}
          start-offset = 30m
          start-offset = ${?POLICIES_SYNCHRONIZATION_START_OFFSET}
          initial-start-offset = 120m
          initial-start-offset = ${?POLICIES_SYNCHRONIZATION_INITIAL_START_OFFSET}
          stream-interval = 5m
          stream-interval = ${?POLICIES_SYNCHRONIZATION_STREAM_INTERVAL}
          outdated-warning-offset = 3h
          outdated-warning-offset = ${?POLICIES_SYNCHRONIZATION_OUTDATED_WARNING_OFFSET}
          outdated-error-offset = 4h
          outdated-error-offset = ${?POLICIES_SYNCHRONIZATION_OUTDATED_ERROR_OFFSET}
          max-idle-time = 1m
          max-idle-time = ${?POLICIES_SYNCHRONIZATION_MAX_IDLE_TIME}
          // streaming actor timeout is set generouslyl because each policy tag may trigger updates at many things.
          streaming-actor-timeout = 30m
          streaming-actor-timeout = ${?POLICIES_SYNCHRONIZATION_STREAMING_ACTOR_TIMEOUT}
          elements-streamed-per-batch = 1
          elements-streamed-per-batch = ${?POLICIES_SYNCHRONIZATION_ELEMENTS_PER_SECOND}
        }
      }
    }
  }

}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "INFO"

  log-config-on-start = off

  discovery.method = akka-dns
  management.cluster.bootstrap {
    contact-point-discovery {
      service-name = "ditto-cluster"
      service-name = ${?CLUSTER_BS_SERVICE_NAME}
      service-namespace = ${?CLUSTER_BS_SERVICE_NAMESPACE}
      effective-name = ${?CLUSTER_BS_EFFECTIVE_NAME}

      required-contact-point-nr = ${?CLUSTER_BS_REQUIRED_CONTACTS}
    }
  }

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    enable-additional-serialization-bindings = on

    # this is only intended for testing.
    serialize-messages = off
    serialize-creators = off

    debug {
      lifecycle = on
    }

    custom-updater-mailbox {
      mailbox-type = "org.eclipse.ditto.services.thingsearch.updater.actors.mailbox.ThingUpdaterMailbox"
      mailbox-capacity = 1000
      mailbox-capacity = ${?UPDATER_MAILBOX_CAPACITY}
      stash-capacity = 1000
      stash-capacity = ${?UPDATER_STASH_CAPACITY}
    }

    default-dispatcher {
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 3.0
        parallelism-max = 32
        parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
      }
    }

    serializers {
      json = "org.eclipse.ditto.services.utils.cluster.JsonifiableSerializer"
    }

    serialization-bindings {
      # "java.io.Serializable" = none # must not be set in order to get akka.cluster.sharding.ShardRegion$GetShardRegionStats$ serialized
      # Serialize Jsonifiable events with custom JSON serializer:
      "org.eclipse.ditto.model.base.json.Jsonifiable" = json
      "org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = json
    }
  }

  extensions = [
    "akka.cluster.pubsub.DistributedPubSub"
  ]

  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = ""
      hostname = ${?TCP_HOSTNAME}
      port = 2551
      port = ${?TCP_PORT}

      bind-hostname = ${?BIND_HOSTNAME}
      bind-port = ${?BIND_TCP_PORT}

      # maximum-frame-size = 128000b # this is the default
      maximum-frame-size = 10485760b # 10MB - things could get that big
      # send-buffer-size = 256000b # this is the default
      send-buffer-size = 20971520b # 20MB
      # receive-buffer-size = 256000b # this is the default
      receive-buffer-size = 20971520b # 20MB
    }
    watch-failure-detector.threshold = 12 # default 10
  }

  cluster {
    # Disable legacy metrics in akka-cluster.
    metrics.enabled = off

    # enable weakly up feature to allow members to join even if some members are unreachable
    allow-weakly-up-members = on

    # required for akka-management-cluster-bootstrap (to be more robust):
    shutdown-after-unsuccessful-join-seed-nodes = 40s

    sharding {
      state-store-mode = ddata
      use-dispatcher = "sharding-dispatcher"

      role = "things-search"
    }

    roles = [
      "things-search"
    ]
  }
}

sharding-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 2.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5 # default is 5
}

search-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 2.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}
