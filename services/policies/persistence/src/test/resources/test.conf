ditto.mapping-strategy.implementation = "org.eclipse.ditto.services.models.policies.PoliciesMappingStrategy"

ditto.policies {
  policy {
    activity.check.interval = 5h
    modification.check.interval = 10s
    snapshot {
      interval = 5m
      threshold = 100
      delete-old = true
    }
    events.delete-old = true
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "INFO"

  log-config-on-start = off

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    enable-additional-serialization-bindings = on

    # this is only intended for testing.
    serialize-messages = off
    serialize-creators = off

    debug {
      lifecycle = on
    }

    guardian-supervisor-strategy = "akka.actor.StoppingSupervisorStrategy"

    serializers {
      json = "org.eclipse.ditto.services.utils.cluster.JsonifiableSerializer"
    }

    serialization-bindings {
      # Serialize Jsonifiable events with custom JSON serializer:
      "org.eclipse.ditto.model.base.json.Jsonifiable" = json
      "org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = json
    }
  }

  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      hostname = "127.0.0.1"
      port = 22551
      port = ${?RANDOM_TEST_PORT}
    }
  }

  cluster {
    metrics.enabled = off
    seed-nodes = ["akka.tcp://AkkaTestSystem@"${akka.remote.netty.tcp.hostname}":"${akka.remote.netty.tcp.port}]

    roles = [
      "policies",
      "policy-cache-aware"
    ]
  }

  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor = 1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 10s

    # duration to wait in expectMsg and friends outside of within() block
    # by default
    single-expect-default = 10s

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 10s

    calling-thread-dispatcher {
      type = akka.testkit.CallingThreadDispatcherConfigurator
    }
  }
}

akka.cluster {
  sharding {
    state-store-mode = ddata
    use-dispatcher = "sharding-dispatcher"

    role = "policies"
  }
}

akka.contrib.persistence.mongodb.mongo {
  driver = "akka.contrib.persistence.mongodb.DittoCasbahPersistenceExtension"
}

akka-contrib-mongodb-persistence-policies-journal {
  class = "akka.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "policy-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.policies.persistence.serializer.MongoPolicyEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.policies.PolicyEvent" = mongodbobject
    "com.mongodb.DBObject" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-policies-snapshots {
  class = "akka.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "policy-persistence-dispatcher"

  ask-timeout = 10s
}

policy-persistence-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 4.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 128
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 2
}

sharding-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 4.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 128
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 2
}
