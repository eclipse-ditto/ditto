ditto {
  mapping-strategy.implementation = "org.eclipse.ditto.services.models.connectivity.ConnectivityMappingStrategy"
  cluster-downing.role = "connectivity"

  connectivity {
    connection {
      snapshot {
        threshold = 5
      }

      flush-pending-responses-timeout = 0s

      kafka.producer.internal { # internal configuration as needed by akka-stream-kafka library
        # Tuning parameter of how many sends that can run in parallel.
        parallelism = 100

        # Duration to wait for `KafkaConsumer.close` to finish.
        close-timeout = 60s

        # Fully qualified config path which holds the dispatcher configuration
        # to be used by the producer stages. Some blocking may occur.
        # When this value is empty, the dispatcher configured for the stream
        # will be used.
        use-dispatcher = "akka.kafka.default-dispatcher"

        # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
        eos-commit-interval = 100ms

        # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
        # can be defined in this configuration section.
        kafka-clients {
        }
      }
    }

    mapping {

      factory = "org.eclipse.ditto.services.connectivity.mapping.MessageMappers"

      javascript {
        maxScriptSizeBytes = 50000 # 50kB
        maxScriptExecutionTime = 500ms
        maxScriptStackDepth = 10
      }
    }

    reconnect {
      snapshot {
        threshold = 5
      }
      # initial delay for reconnecting the connections after the ReconnectActor has been started.
      initial-delay = 0s
      initial-delay = ${?RECONNECT_INITIAL_DELAY}
      # interval for trying to reconnect all started connections.
      interval = 10m
      interval = ${?RECONNECT_INTERVAL}

      # used to throttle the recovery of connections, so that not all connections are recovered at the same time
      rate {
        frequency = 1s
        frequency = ${?RECONNECT_RATE_FREQUENCY}
        entities = 2
        entities = ${?RECONNECT_RATE_ENTITIES}
      }
    }

    client.init-timeout = 1s
  }

}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "WARNING"

  log-config-on-start = off

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    enable-additional-serialization-bindings = on

    # this is only intended for testing.
    serialize-messages = off
    serialize-creators = off

    debug {
      lifecycle = on
    }

    default-dispatcher {
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 3.0
        parallelism-max = 32
        parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
      }
    }

    serializers {
      json = "org.eclipse.ditto.services.utils.cluster.JsonifiableSerializer"
    }

    serialization-bindings {
      # "java.io.Serializable" = none # must not be set in order to get akka.cluster.sharding.ShardRegion$GetShardRegionStats$ serialized
      # Serialize Jsonifiable events with custom JSON serializer:
      "org.eclipse.ditto.model.base.json.Jsonifiable" = json
      "org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = json
    }
  }

  extensions = [
    "akka.cluster.pubsub.DistributedPubSub"
  ]

  remote {
    log-remote-lifecycle-events = on
    artery {
      enabled = on
      transport = tcp
      canonical {
        # InetAddress.getLocalHost.getHostAddress is used if empty
        hostname = "127.0.0.1"
        hostname = ${?REMOTE_HOSTNAME}
        port = 0
        port = ${?REMOTE_PORT}
      }
      bind {
        hostname = ${?BIND_HOSTNAME}
        port = ${?BIND_REMOTE_PORT}
      }
    }
  }

  cluster {
    # Disable legacy metrics in akka-cluster.
    metrics.enabled = off

    # enable weakly up feature to allow members to join even if some members are unreachable
    allow-weakly-up-members = on

    # required for akka-management-cluster-bootstrap (to be more robust):
    shutdown-after-unsuccessful-join-seed-nodes = 40s

    sharding {
      state-store-mode = ddata
      use-dispatcher = "sharding-dispatcher"

      role = "connectivity"
    }

    roles = [
      "connectivity"
    ]
  }

  http {
    server {
      server-header = "" # default: akka-http/${akka.http.version}
      max-connections = 4096 # default: 1024
      backlog = 100 # default: 100

      parsing {
        max-uri-length = 8k # default: 2k
        max-content-length = 10m # default: 8m
        illegal-header-warnings = off # default: on
        error-logging-verbosity = simple # default: full
      }
    }

    host-connection-pool {
      # The maximum number of open requests accepted into the pool across all
      # materializations of any of its client flows.
      # Protects against (accidentally) overloading a single pool with too many client flow materializations.
      # Note that with N concurrent materializations the max number of open request in the pool
      # will never exceed N * max-connections * pipelining-limit.
      # Must be a power of 2 and > 0!
      max-open-requests = 1024 # default: 32

      # The time after which an idle connection pool (without pending requests)
      # will automatically terminate itself. Set to `infinite` to completely disable idle timeouts.
      idle-timeout = 60s # default: 30s
    }
  }

  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor = 1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 3s

    # duration to wait in expectMsg and friends outside of within() block
    # by default
    single-expect-default = 3s

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 5s

    calling-thread-dispatcher {
      type = akka.testkit.CallingThreadDispatcherConfigurator
    }
  }
}

akka-contrib-mongodb-persistence-connection-journal {
  class = "akka.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.connectivity.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-connection-snapshots {
  class = "akka.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s
}

akka-contrib-mongodb-persistence-reconnect-journal {
  class = "akka.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.connectivity.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-reconnect-snapshots {
  class = "akka.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s
}

connection-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 3.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

reconnect-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 3.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

message-mapping-processor-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 4.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  throughput = 5
}

jms-connection-handling-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}
