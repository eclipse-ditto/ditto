ditto {
  mapping-strategy.implementation = "org.eclipse.ditto.services.models.connectivity.ConnectivityMappingStrategy"

  connectivity {
    connection {

      snapshot {
        threshold = 5
      }
    }

    mapping {
      javascript {
        maxScriptSizeBytes = 50000 # 50kB
        maxScriptExecutionTime = 500ms
        maxScriptStackDepth = 10
      }
    }

    reconnect {
      snapshot {
        threshold = 5
      }
    }

    client.init-timeout = 1s

    message {
      header-blacklist = []
    }
  }

}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  # for log messages during the actor system is starting up and shutting down:
  stdout-loglevel = "WARNING"

  log-config-on-start = off

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    enable-additional-serialization-bindings = on

    # this is only intended for testing.
    serialize-messages = off
    serialize-creators = off

    debug {
      lifecycle = on
    }

    default-dispatcher {
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 3.0
        parallelism-max = 32
        parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
      }
    }

    serializers {
      json = "org.eclipse.ditto.services.utils.cluster.JsonifiableSerializer"
    }

    serialization-bindings {
      # "java.io.Serializable" = none # must not be set in order to get akka.cluster.sharding.ShardRegion$GetShardRegionStats$ serialized
      # Serialize Jsonifiable events with custom JSON serializer:
      "org.eclipse.ditto.model.base.json.Jsonifiable" = json
      "org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = json
    }
  }

  extensions = [
    "akka.cluster.pubsub.DistributedPubSub"
  ]

  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = ""
      hostname = ${?TCP_HOSTNAME}
      port = 0
      port = ${?TCP_PORT}

      bind-hostname = ${?BIND_HOSTNAME}
      bind-port = ${?BIND_TCP_PORT}

      # maximum-frame-size = 128000b # this is the default
      maximum-frame-size = 10485760b # 10MB - things could get that big
      # send-buffer-size = 256000b # this is the default
      send-buffer-size = 20971520b # 20MB
      # receive-buffer-size = 256000b # this is the default
      receive-buffer-size = 20971520b # 20MB
    }
  }

  cluster {
    # Disable legacy metrics in akka-cluster.
    metrics.enabled = off

    # enable weakly up feature to allow members to join even if some members are unreachable
    allow-weakly-up-members = on

    # required for akka-management-cluster-bootstrap (to be more robust):
    shutdown-after-unsuccessful-join-seed-nodes = 40s

    sharding {
      state-store-mode = ddata
      use-dispatcher = "sharding-dispatcher"

      role = "connectivity"
    }

    roles = [
      "connectivity"
    ]
  }

  http {
    server {
      server-header = "" # default: akka-http/${akka.http.version}
      max-connections = 4096 # default: 1024
      backlog = 100 # default: 100

      parsing {
        max-uri-length = 8k # default: 2k
        max-content-length = 10m # default: 8m
        illegal-header-warnings = off # default: on
        error-logging-verbosity = simple # default: full
      }
    }

    host-connection-pool {
      # The maximum number of open requests accepted into the pool across all
      # materializations of any of its client flows.
      # Protects against (accidentally) overloading a single pool with too many client flow materializations.
      # Note that with N concurrent materializations the max number of open request in the pool
      # will never exceed N * max-connections * pipelining-limit.
      # Must be a power of 2 and > 0!
      max-open-requests = 1024 # default: 32

      # The time after which an idle connection pool (without pending requests)
      # will automatically terminate itself. Set to `infinite` to completely disable idle timeouts.
      idle-timeout = 60s # default: 30s
    }
  }

  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor = 1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 3s

    # duration to wait in expectMsg and friends outside of within() block
    # by default
    single-expect-default = 3s

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 5s

    calling-thread-dispatcher {
      type = akka.testkit.CallingThreadDispatcherConfigurator
    }
  }
}

akka-contrib-mongodb-persistence-connection-journal {
  class = "akka.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.connectivity.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "com.mongodb.DBObject" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-connection-snapshots {
  class = "akka.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "connection-persistence-dispatcher"

  ask-timeout = 10s
}

akka-contrib-mongodb-persistence-reconnect-journal {
  class = "akka.persistence.inmemory.journal.InMemoryAsyncWriteJournal"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.connectivity.messaging.persistence.ConnectivityMongoEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "com.mongodb.DBObject" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-reconnect-snapshots {
  class = "akka.persistence.inmemory.snapshot.InMemorySnapshotStore"
  plugin-dispatcher = "reconnect-persistence-dispatcher"

  ask-timeout = 10s
}

connection-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 2.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 2
}

reconnect-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 2.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 2
}

message-mapping-processor-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 4.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 2
}
