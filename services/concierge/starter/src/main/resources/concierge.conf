ditto {
  concierge {
    http {
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = ""
      hostname = ${?HOSTNAME}
      hostname = ${?BIND_HOSTNAME}
      port = 8080
      port = ${?HTTP_PORT}
      port = ${?PORT}
    }

    cluster {
      # as a rule of thumb: should be factor ten of the amount of cluster nodes available
      # be aware that it must be the same as for all other services (e.g. search-updater)
      number-of-shards = 30
      number-of-shards = ${?CLUSTER_NUMBER_OF_SHARDS}
    }

    metrics {
      systemMetrics.enabled = true
      systemMetrics.enabled = ${?SYSTEM_METRICS_ENABLED}

      prometheus {
        enabled = true
        enabled = ${?PROMETHEUS_ENABLED}
        hostname = 0.0.0.0
        hostname = ${?PROMETHEUS_HOSTNAME}
        port = 9095
        port = ${?PROMETHEUS_PORT}
      }
    }

    enforcement {
      # maximum duration to wait for anwers from entity shard regions
      ask-timeout = 30s
      ask-timeout = ${?ENFORCEMENT_ASK_TIMEOUT}

      # the buffer size used for the queue in the enforcement actor
      # after this limit is reached, the mailbox of the enforcement actor will rise and buffer messages
      buffer-size = 1000
      buffer-size = ${?ENFORCEMENT_BUFFER_SIZE}

      # parallelism to use for processing messages in parallel in the enforcement actor
      # when configured too low, throughput of messages which perform blocking operations will be bad
      parallelism = 100
      buffer-size = ${?ENFORCEMENT_PARALLELISM}
    }

    caches {
      # maximum duration to wait for entity shard regions for cache update
      ask-timeout = 30s
      ask-timeout = ${?CONCIERGE_CACHES_ASK_TIMEOUT}

      id {
        # how many relations to cache
        maximum-size = 80000
        maximum-size = ${?AUTHORIZATION_ID_CACHE_SIZE}

        # maximum duration of inconsistency after losing a cache invalidation
        expire-after-write = 1h
        expire-after-write = ${?EXPIRE_AFTER_WRITE_ID_CACHE}

        # prolonged on each cache access by that duration
        expire-after-access = 15m
        expire-after-access = ${?EXPIRE_AFTER_ACCESS_ID_CACHE}
      }

      enforcer {
        # how many enforcers to cache
        maximum-size = 20000
        maximum-size = ${?AUTHORIZATION_ENFORCER_CACHE_SIZE}

        # maximum duration of inconsistency after losing a cache invalidation
        expire-after-write = 1h
        expire-after-write = ${?EXPIRE_AFTER_WRITE_ENFORCER_CACHE}

        # prolonged on each cache access by that duration
        expire-after-access = 15m
        expire-after-access = ${?EXPIRE_AFTER_ACCESS_ENFORCER_CACHE}
      }
    }

    things-aggregator {
      single-retrieve-thing-timeout = 30s
      single-retrieve-thing-timeout = ${?THINGS_AGGREGATOR_SINGLE_RETRIEVE_THING_TIMEOUT}
      max-parallelism = 20
      max-parallelism = ${?THINGS_AGGREGATOR_MAX_PARALLELISM}
    }

    health-check {
      enabled = true
      enabled = ${?HEALTH_CHECK_ENABLED} # may be overridden with this environment variable
      interval = 60s

      persistence {
        enabled = true
        enabled = ${?HEALTH_CHECK_PERSISTENCE_ENABLED} # may be overridden with this environment variable
        timeout = 60s
      }
    }
  }
}

akka.cluster.distributed-data {
  ditto-replicator-facade {
    read-timeout = 5s
    write-timeout = 25s
  }
}

akka {
  actor {
    deployment {
      /conciergeRoot/dispatcherActor/aggregator {
        router = round-robin-pool
        # nr-of-instances = 5
        resizer {
          lower-bound = 5
          upper-bound = 100
          messages-per-resize = 50
        }
      }
    }
  }

  cluster {
    sharding {
      role = "concierge"
    }

    roles = [
      "concierge",
      "blocked-namespaces-aware"
    ]
  }
}


aggregator-internal-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

batch-persistence-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

cached-namespace-invalidator-dispatcher {
  # one thread per actor in case the actor blocks.
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

blocked-namespaces-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

enforcer-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

thing-id-cache-dispatcher {
    type = "Dispatcher"
    executor = "thread-pool-executor"
    thread-pool-executor {
        keep-alive-time = 60s
        fixed-pool-size = off
        max-pool-size-max = 256
        max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
        max-pool-size-max = ${?THING_ID_CACHE_DISPATCHER_POOL_SIZE_MAX}
    }
}

policy-enforcer-cache-dispatcher {
    type = "Dispatcher"
    executor = "thread-pool-executor"
    thread-pool-executor {
        keep-alive-time = 60s
        fixed-pool-size = off
        max-pool-size-max = 256
        max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
        max-pool-size-max = ${?POLICY_ENFORCER_CACHE_DISPATCHER_POOL_SIZE_MAX}
    }
}

acl-enforcer-cache-dispatcher {
    type = "Dispatcher"
    executor = "thread-pool-executor"
    thread-pool-executor {
        keep-alive-time = 60s
        fixed-pool-size = off
        max-pool-size-max = 256
        max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
        max-pool-size-max = ${?ACL_ENFORCER_CACHE_DISPATCHER_POOL_SIZE_MAX}
    }
}

akka-contrib-mongodb-persistence-batch-journal {
  class = "akka.contrib.persistence.mongodb.MongoJournal"
  plugin-dispatcher = "batch-persistence-dispatcher"

  overrides {
    journal-collection = "batch_journal"
    journal-index = "batch_journal_index"

    realtime-collection = "batch_realtime"
    metadata-collection = "batch_metadata"
  }

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.concierge.batch.MongoBatchEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-batch-snapshots {
  class = "akka.contrib.persistence.mongodb.MongoSnapshots"
  plugin-dispatcher = "batch-persistence-dispatcher"

  overrides {
    snaps-collection = "batch_snaps"
    snaps-index = "batch_snaps_index"
  }
}

akka-contrib-mongodb-persistence-batch-supervisor-journal {
  class = "akka.contrib.persistence.mongodb.MongoJournal"
  plugin-dispatcher = "batch-persistence-dispatcher"

  overrides {
    journal-collection = "batch_supervisor_journal"
    journal-index = "batch_supervisor_journal_index"

    realtime-collection = "batch_supervisor_realtime"
    metadata-collection = "batch_supervisor_metadata"
  }

  event-adapters {
    mongodbobject = "org.eclipse.ditto.services.concierge.batch.MongoBatchEventAdapter"
  }

  event-adapter-bindings {
    "org.eclipse.ditto.signals.events.base.Event" = mongodbobject
    "org.bson.BsonValue" = mongodbobject
  }
}

akka-contrib-mongodb-persistence-batch-supervisor-snapshots {
  class = "akka.contrib.persistence.mongodb.MongoSnapshots"
  plugin-dispatcher = "batch-persistence-dispatcher"

  overrides {
    snaps-collection = "batch_supervisor_snaps"
    snaps-index = "batch_supervisor_snaps_index"
  }
}

include "concierge-extension"
