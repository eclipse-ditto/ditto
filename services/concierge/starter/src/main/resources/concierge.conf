ditto {
  mongodb {
    hostname = "localhost"
    hostname = ${?MONGO_DB_HOSTNAME}
    port = 27017
    port = ${?MONGO_DB_PORT}
    authentication = ${?MONGO_DB_AUTHENTICATION}
    database = "concierge"
    database = ${?MONGO_DB_DATABASE}

    options {
      ssl = false
      ssl = ${?MONGO_DB_SSL_ENABLED}
      w = 1
    }
  }

  concierge {
    enforcement {
      # maximum duration to wait for anwers from entity shard regions
      ask-timeout = 30s
      ask-timeout = ${?ENFORCEMENT_ASK_TIMEOUT}

      # the buffer size used for the queue in the enforcement actor
      buffer-size = 2000
      buffer-size = ${?ENFORCEMENT_BUFFER_SIZE}

      # parallelism to use for processing messages in parallel in the enforcement actor
      # when configured too low, throughput of messages which perform blocking operations will be bad
      parallelism = 256
      parallelism = ${?ENFORCEMENT_PARALLELISM}
    }

    caches {
      # maximum duration to wait for entity shard regions for cache update
      ask-timeout = 30s
      ask-timeout = ${?CONCIERGE_CACHES_ASK_TIMEOUT}

      id {
        # how many relations to cache
        maximum-size = 80000
        maximum-size = ${?AUTHORIZATION_ID_CACHE_SIZE}

        # maximum duration of inconsistency after losing a cache invalidation
        expire-after-write = 1h
        expire-after-write = ${?EXPIRE_AFTER_WRITE_ID_CACHE}

        # prolonged on each cache access by that duration
        expire-after-access = 15m
        expire-after-access = ${?EXPIRE_AFTER_ACCESS_ID_CACHE}
      }

      enforcer {
        # how many enforcers to cache
        maximum-size = 20000
        maximum-size = ${?AUTHORIZATION_ENFORCER_CACHE_SIZE}

        # maximum duration of inconsistency after losing a cache invalidation
        expire-after-write = 1h
        expire-after-write = ${?EXPIRE_AFTER_WRITE_ENFORCER_CACHE}

        # prolonged on each cache access by that duration
        expire-after-access = 15m
        expire-after-access = ${?EXPIRE_AFTER_ACCESS_ENFORCER_CACHE}
      }
    }

    things-aggregator {
      single-retrieve-thing-timeout = 30s
      single-retrieve-thing-timeout = ${?THINGS_AGGREGATOR_SINGLE_RETRIEVE_THING_TIMEOUT}
      max-parallelism = 20
      max-parallelism = ${?THINGS_AGGREGATOR_MAX_PARALLELISM}
    }

    persistence-cleanup {

      enabled = true
      enabled = ${?PERSISTENCE_CLEANUP_ENABLED}

      quiet-period = 5m
      quiet-period = ${?PERSISTENCE_CLEANUP_QUIET_PERIOD}

      cleanup-timeout = 120s
      cleanup-timeout = ${?PERSISTENCE_CLEANUP_CLEANUP_TIMEOUT}

      parallelism = 1
      parallelism = ${?PERSISTENCE_CLEANUP_PARALLELISM}

      keep {
        credit-decisions = 30
        credit-decisions = ${?PERSISTENCE_CLEANUP_KEEP_CREDIT_DECISIONS}

        actions = 120
        actions = ${?PERSISTENCE_CLEANUP_KEEP_ACTIONS}

        events = 15
        events = ${?PERSISTENCE_CLEANUP_KEEP_EVENTS}
      }

      credit-decision {
        interval = 10s
        interval = ${?PERSISTENCE_CLEANUP_DECISION_INTERVAL}

        metric-report-timeout = 10s
        metric-report-timeout = ${?PERSISTENCE_CLEANUP_DECISION_METRIC_REPORT_TIMEOUT}

        timer-threshold = 20ms
        timer-threshold = ${?PERSISTENCE_CLEANUP_DECISION_TIMER_THRESHOLD}

        # how many cleanup actions may be run concurrently whenever the max roundtriptimes against MongoDB are below the
        #  configured "timer-threshold"
        credit-per-batch = 5
        credit-per-batch = ${?PERSISTENCE_CLEANUP_DECISION_CREDIT_PER_BATCH}
      }

      persistence-ids {
        burst = 25
        burst = ${?PERSISTENCE_CLEANUP_PIDS_BURST}

        stream-request-timeout = 10s
        stream-request-timeout = ${?PERSISTENCE_CLEANUP_PIDS_STREAM_REQUEST_TIMEOUT}

        # includes maximum duration during which no credit was given out
        stream-idle-timeout = 3h
        stream-idle-timeout = ${?PERSISTENCE_CLEANUP_PIDS_STREAM_IDLE_TIMEOUT}

        # handle failures/stalling/expired cursors
        min-backoff = 1s
        min-backoff = ${?PERSISTENCE_CLEANUP_PIDS_MIN_BACKOFF}

        max-backoff = 2m
        max-backoff = ${?PERSISTENCE_CLEANUP_PIDS_MAX_BACKOFF}

        max-restarts = 180 // give up stream resumption after about 6 hours = 180 * 120s
        max-restarts = ${?PERSISTENCE_CLEANUP_PIDS_MAX_RESTARTS}

        recovery = 4m // assume upstream healthy if no error happened for this long
        recovery = ${?PERSISTENCE_CLEANUP_PIDS_RECOCVERY}
      }
    }
  }
}

akka {
  actor {
    deployment {
      /conciergeRoot/dispatcherActor/aggregator {
        router = round-robin-pool
        # nr-of-instances = 5
        resizer {
          lower-bound = 5
          upper-bound = 100
          messages-per-resize = 50
        }
      }
    }
  }

  cluster {
    sharding {
      role = "concierge"
    }

    roles = [
      "concierge",
      "blocked-namespaces-aware",
      "live-signal-aware"
    ]
  }
}

aggregator-internal-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

cached-namespace-invalidator-dispatcher {
  # one thread per actor in case the actor blocks.
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}

blocked-namespaces-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

thing-id-cache-dispatcher {
  type = "Dispatcher"
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = off
    max-pool-size-max = 256
    max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
    max-pool-size-max = ${?THING_ID_CACHE_DISPATCHER_POOL_SIZE_MAX}
  }
}

policy-enforcer-cache-dispatcher {
  type = "Dispatcher"
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = off
    max-pool-size-max = 256
    max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
    max-pool-size-max = ${?POLICY_ENFORCER_CACHE_DISPATCHER_POOL_SIZE_MAX}
  }
}

acl-enforcer-cache-dispatcher {
  type = "Dispatcher"
  executor = "thread-pool-executor"
  thread-pool-executor {
    keep-alive-time = 60s
    fixed-pool-size = off
    max-pool-size-max = 256
    max-pool-size-max = ${?CACHE_DISPATCHER_POOL_SIZE_MAX}
    max-pool-size-max = ${?ACL_ENFORCER_CACHE_DISPATCHER_POOL_SIZE_MAX}
  }
}

include "concierge-extension"
